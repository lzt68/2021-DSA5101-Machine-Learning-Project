{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selcetion: Random Forest vs Decision Tree\n",
    "\n",
    "This notebook will carry on the comparison between random forest and decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Non-preprocessing + one-hot encoding + grid search\n",
    "\n",
    "Firstlly, we will compare the performance of RF and DT in the case of non-preprocessing and normal one-hot encoding.\n",
    "\n",
    "We will use the **origin dataset** without feature \"year\" and \"timestamp\", and then we will use **one-hot encoding** to transform categorical features.\n",
    "\n",
    "We carry on elementry grid search to find the best parametes, and then we will compare the best mcc score of these two models.\n",
    "\n",
    "Results:\n",
    "> Decision Tree: 0.5098119472523316 <br> \n",
    "> Random Forest: **0.5588019423045544**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the module\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data=pd.read_csv(\"..\\\\bank-full.csv\", sep=';', engine=\"python\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown = 'ignore', sparse = True)\n",
    "y = data['y'].replace({\"yes\":1,\"no\":0})\n",
    "data.drop(columns = ['y'], inplace = True)\n",
    "\n",
    "integer_list = []\n",
    "discrete_list = []\n",
    "for col in data.columns:\n",
    "#     print(col, \":\", data[col].dtype)    \n",
    "    if data[col].dtype == \"object\":\n",
    "        discrete_list.append(col)\n",
    "    else:\n",
    "        integer_list.append(col)\n",
    "        data[col] = data[col].astype(float)\n",
    "X = pd.get_dummies(data, columns=discrete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}\n",
      "0.5098119472523316\n",
      "{'mean_fit_time': array([0.12431231, 0.15954905, 0.17810616, 0.34561911, 0.46528525,\n",
      "       0.14181929, 0.1728723 , 0.19539142, 0.34318576, 0.44814696,\n",
      "       0.12246718, 0.15562434, 0.17479501, 0.31853724, 0.43235998,\n",
      "       0.13992481, 0.15149541, 0.20238571, 0.33012881, 0.43746076,\n",
      "       0.12838612, 0.15645957, 0.20508761, 0.34499626, 0.44610162,\n",
      "       0.15135589, 0.14920926, 0.17517319, 0.30784187, 0.389217  ,\n",
      "       0.1128479 , 0.1490231 , 0.17394395, 0.29134784, 0.40618424,\n",
      "       0.12351317, 0.15229602, 0.17830677, 0.30726352, 0.3829875 ,\n",
      "       0.1185441 , 0.14719186, 0.17588415, 0.32890048, 0.43937979,\n",
      "       0.13105111, 0.15995789, 0.18870816, 0.32053919, 0.40891008]), 'std_fit_time': array([0.00133722, 0.00302426, 0.00764502, 0.02307031, 0.02638922,\n",
      "       0.00410458, 0.01312648, 0.01009747, 0.02389502, 0.02335148,\n",
      "       0.00643217, 0.00390046, 0.00933061, 0.01802625, 0.02172583,\n",
      "       0.02192434, 0.0098157 , 0.0268781 , 0.00600039, 0.0175205 ,\n",
      "       0.00618618, 0.01104074, 0.02279658, 0.01707989, 0.05578711,\n",
      "       0.02663911, 0.00800381, 0.00452496, 0.01266917, 0.00469437,\n",
      "       0.00429532, 0.00683742, 0.00507236, 0.00594596, 0.01399497,\n",
      "       0.00669985, 0.00605711, 0.00620072, 0.00598542, 0.01020619,\n",
      "       0.00870781, 0.00599958, 0.00911736, 0.03446757, 0.02097242,\n",
      "       0.00313493, 0.00265097, 0.00628393, 0.00598731, 0.01825384]), 'mean_score_time': array([0.01561842, 0.01833906, 0.01559834, 0.01786847, 0.01890244,\n",
      "       0.0191525 , 0.01774058, 0.01860552, 0.02223544, 0.02187672,\n",
      "       0.01749063, 0.01815982, 0.0143445 , 0.01756659, 0.02352109,\n",
      "       0.0204823 , 0.01669607, 0.02209435, 0.01599188, 0.01835141,\n",
      "       0.01839366, 0.01794848, 0.01907544, 0.01788411, 0.02118669,\n",
      "       0.01708083, 0.01577234, 0.01597366, 0.01811767, 0.01811438,\n",
      "       0.01563153, 0.01867776, 0.01379485, 0.02120585, 0.01900344,\n",
      "       0.0158988 , 0.01668277, 0.01561017, 0.01863699, 0.01875191,\n",
      "       0.02067261, 0.01356487, 0.01519918, 0.01862097, 0.01713896,\n",
      "       0.01754518, 0.01696897, 0.01755161, 0.01776299, 0.01796637]), 'std_score_time': array([2.54840800e-05, 4.02042395e-03, 1.17986126e-05, 1.21724181e-03,\n",
      "       3.12980000e-03, 3.48384435e-03, 9.73275787e-04, 3.12181422e-03,\n",
      "       7.14831434e-03, 4.14332407e-03, 9.34278459e-04, 9.51592813e-04,\n",
      "       5.10352018e-03, 1.62206636e-03, 7.31327470e-03, 3.15761547e-03,\n",
      "       1.20838080e-03, 6.71133429e-03, 6.02289023e-03, 1.35063195e-03,\n",
      "       2.84020107e-03, 6.66998756e-03, 3.41884072e-03, 1.75213179e-03,\n",
      "       6.55340951e-03, 3.32845309e-03, 1.26921615e-03, 7.29115802e-04,\n",
      "       6.84546155e-03, 7.04769873e-03, 1.06779588e-05, 2.86244774e-03,\n",
      "       4.36925585e-03, 6.91092570e-03, 6.12881109e-03, 5.23337299e-04,\n",
      "       9.18206605e-03, 2.22286938e-05, 6.32448415e-03, 6.22736653e-03,\n",
      "       5.06569970e-03, 5.88840845e-03, 6.24104813e-04, 3.35783576e-03,\n",
      "       2.40319555e-03, 1.01404912e-03, 6.22164454e-04, 1.34286059e-03,\n",
      "       1.31798412e-03, 1.08814489e-03]), 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', None, None, None, None, None,\n",
      "                   None, None, None, None, None, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3,\n",
      "                   4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4,\n",
      "                   5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5,\n",
      "                   10, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_random_state': masked_array(data=[888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}], 'split0_test_score': array([0.39710017, 0.40101753, 0.43225184, 0.51612698, 0.48230216,\n",
      "       0.3936463 , 0.39307811, 0.46516338, 0.47191944, 0.47042201,\n",
      "       0.40383006, 0.4276534 , 0.44066953, 0.44147196, 0.43436551,\n",
      "       0.4269982 , 0.39585785, 0.41709056, 0.4425412 , 0.4725657 ,\n",
      "       0.47231785, 0.46424572, 0.47456563, 0.53199594, 0.47927754,\n",
      "       0.43625125, 0.46440423, 0.4669938 , 0.51722972, 0.47482916,\n",
      "       0.45619741, 0.4605889 , 0.46469346, 0.51974943, 0.47791182,\n",
      "       0.40495799, 0.40456766, 0.47175681, 0.50440512, 0.48777659,\n",
      "       0.47231785, 0.46424572, 0.47456563, 0.50332505, 0.476259  ,\n",
      "       0.43625125, 0.4635367 , 0.47075855, 0.51338135, 0.47112   ]), 'split1_test_score': array([0.38620233, 0.39108903, 0.4607541 , 0.48394989, 0.49641655,\n",
      "       0.38376324, 0.38280434, 0.44221392, 0.47348291, 0.46214667,\n",
      "       0.42933255, 0.44512901, 0.44673396, 0.43711309, 0.4194249 ,\n",
      "       0.42933255, 0.42816637, 0.43666496, 0.44171523, 0.43714082,\n",
      "       0.46003969, 0.46381915, 0.4710393 , 0.50056372, 0.4862171 ,\n",
      "       0.42635046, 0.46729099, 0.47226122, 0.50071969, 0.48605826,\n",
      "       0.45226745, 0.45320653, 0.44418695, 0.51690368, 0.50007178,\n",
      "       0.38376324, 0.44717815, 0.44408014, 0.5019262 , 0.46995616,\n",
      "       0.46003969, 0.46381915, 0.47108024, 0.50896796, 0.47640233,\n",
      "       0.42635046, 0.46636185, 0.47226122, 0.50331782, 0.48108489]), 'split2_test_score': array([0.37524862, 0.37925089, 0.45184925, 0.49157523, 0.48624404,\n",
      "       0.36798596, 0.36934106, 0.43994063, 0.46286342, 0.463023  ,\n",
      "       0.42922574, 0.46629106, 0.41170594, 0.44189804, 0.42817069,\n",
      "       0.42922574, 0.45075041, 0.40719063, 0.42839547, 0.44287139,\n",
      "       0.44495025, 0.45293696, 0.46154915, 0.4900395 , 0.46750819,\n",
      "       0.42169487, 0.4479628 , 0.44944141, 0.50353128, 0.46258271,\n",
      "       0.43047901, 0.4336844 , 0.42845062, 0.49183104, 0.4861493 ,\n",
      "       0.3702946 , 0.45054901, 0.44562511, 0.48010534, 0.47550737,\n",
      "       0.44495025, 0.45293696, 0.46154915, 0.49039897, 0.46096891,\n",
      "       0.4114723 , 0.45189432, 0.45644189, 0.50823321, 0.46725049]), 'split3_test_score': array([0.38603533, 0.38777547, 0.38895988, 0.46568703, 0.45036645,\n",
      "       0.37636754, 0.37652227, 0.42647263, 0.45399872, 0.45449496,\n",
      "       0.38705029, 0.43189578, 0.4037667 , 0.39899853, 0.4153976 ,\n",
      "       0.38705029, 0.42225224, 0.4022065 , 0.42077497, 0.45235231,\n",
      "       0.42000377, 0.43243994, 0.44141586, 0.49358199, 0.466961  ,\n",
      "       0.42000377, 0.42850766, 0.43543698, 0.47544981, 0.48191653,\n",
      "       0.43679706, 0.44026023, 0.44846155, 0.48636002, 0.45953672,\n",
      "       0.38609184, 0.38519548, 0.43122877, 0.48243164, 0.4619198 ,\n",
      "       0.42000377, 0.43243994, 0.44141586, 0.49447668, 0.47702552,\n",
      "       0.42000377, 0.42850766, 0.43543698, 0.47898118, 0.49014688]), 'split4_test_score': array([0.37658348, 0.3820268 , 0.45631516, 0.51345333, 0.48842899,\n",
      "       0.37287459, 0.37397419, 0.45003519, 0.49230028, 0.48399429,\n",
      "       0.41994062, 0.41522334, 0.39775089, 0.43972606, 0.45273897,\n",
      "       0.40898318, 0.40079908, 0.41761458, 0.42954159, 0.45633655,\n",
      "       0.45617567, 0.45412446, 0.48505241, 0.53287858, 0.50589407,\n",
      "       0.44616455, 0.47400224, 0.47254039, 0.5262185 , 0.49566396,\n",
      "       0.43800395, 0.44305708, 0.43730286, 0.51328948, 0.48684032,\n",
      "       0.37658348, 0.45880856, 0.45423249, 0.51121031, 0.49724232,\n",
      "       0.44978326, 0.47206114, 0.4852818 , 0.53091182, 0.50062775,\n",
      "       0.44616455, 0.47400224, 0.46868122, 0.52878585, 0.4955825 ]), 'mean_test_score': array([0.38423399, 0.38823194, 0.43802604, 0.49415849, 0.48075164,\n",
      "       0.37892753, 0.37914399, 0.44476515, 0.47091295, 0.46681619,\n",
      "       0.41387585, 0.43723852, 0.42012541, 0.43184154, 0.43001953,\n",
      "       0.41631799, 0.41956519, 0.41615344, 0.43259369, 0.45225336,\n",
      "       0.45069745, 0.45351325, 0.46672447, 0.50981195, 0.48117158,\n",
      "       0.43009298, 0.45643358, 0.45933476, 0.5046298 , 0.48021013,\n",
      "       0.44274898, 0.44615943, 0.44461909, 0.50562673, 0.48210199,\n",
      "       0.38433823, 0.42925977, 0.44938466, 0.49601572, 0.47848045,\n",
      "       0.44941896, 0.45710058, 0.46677854, 0.5056161 , 0.4782567 ,\n",
      "       0.42804846, 0.45686056, 0.46071597, 0.50653988, 0.48103695]), 'std_test_score': array([0.00789842, 0.00762897, 0.02639306, 0.01884897, 0.01587553,\n",
      "       0.00897704, 0.00821286, 0.01271426, 0.01277436, 0.00996087,\n",
      "       0.01632078, 0.01738618, 0.01984535, 0.01650755, 0.01314934,\n",
      "       0.01649517, 0.01983897, 0.01182019, 0.00835198, 0.01221215,\n",
      "       0.01766274, 0.01154286, 0.01471954, 0.01878345, 0.01434486,\n",
      "       0.00982391, 0.01638099, 0.01462276, 0.01727887, 0.01109607,\n",
      "       0.00979749, 0.00956998, 0.01210684, 0.01376129, 0.01333038,\n",
      "       0.01171273, 0.02897859, 0.01338599, 0.01244073, 0.01260305,\n",
      "       0.01745001, 0.01375132, 0.01477922, 0.01422677, 0.01271437,\n",
      "       0.01214782, 0.01585707, 0.01381945, 0.0162137 , 0.01079795]), 'rank_test_score': array([48, 46, 33,  7, 11, 50, 49, 30, 15, 16, 45, 34, 41, 36, 38, 43, 42,\n",
      "       44, 35, 25, 26, 24, 18,  1,  9, 37, 23, 20,  5, 12, 32, 29, 31,  3,\n",
      "        8, 47, 39, 28,  6, 13, 27, 21, 17,  4, 14, 40, 22, 19,  2, 10])}\n"
     ]
    }
   ],
   "source": [
    "# decision tree + grid search\n",
    "\n",
    "myscorer = make_scorer(matthews_corrcoef)\n",
    "parameters = {'criterion':['gini','entropy'],\\\n",
    "              'max_depth':[3, 4, 5, 10, 15],\\\n",
    "              'class_weight':['balanced', None, {0: 1, 1: 2}, {0: 1, 1: 5},{0: 1, 1: 2.125}],\n",
    "              'random_state': [888]}\n",
    "mygridsearch = GridSearchCV(estimator = DecisionTreeClassifier(),\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888))\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)\n",
    "print(mygridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best score of decision tree under this case is 0.5098119472523316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "{'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}\n",
      "0.5588019423045544\n",
      "{'mean_fit_time': array([2.05630946, 4.05401502, 1.83057032, 3.59292283, 1.7594883 ,\n",
      "       3.37653456, 1.89624243, 3.73819094, 1.8766932 , 3.64491749,\n",
      "       1.8237277 , 3.31776886, 1.93926311, 3.7764524 , 1.78848219,\n",
      "       3.51427512, 1.69426656, 3.29046884]), 'std_fit_time': array([0.15705851, 0.15390949, 0.01745648, 0.02740729, 0.04439821,\n",
      "       0.0162666 , 0.01499247, 0.04930504, 0.01465659, 0.10917145,\n",
      "       0.10084598, 0.01826004, 0.03537739, 0.04635801, 0.02047246,\n",
      "       0.0182088 , 0.01829132, 0.0136918 ]), 'mean_score_time': array([0.08593593, 0.15504127, 0.07897964, 0.14683743, 0.08288908,\n",
      "       0.12868552, 0.08494744, 0.15076909, 0.08198562, 0.1497438 ,\n",
      "       0.08482213, 0.13432693, 0.08464894, 0.14903917, 0.09059319,\n",
      "       0.14372811, 0.07184615, 0.14060597]), 'std_score_time': array([1.08558027e-02, 1.14267214e-02, 1.76592099e-03, 7.66502608e-03,\n",
      "       7.02872535e-03, 6.21006279e-03, 7.24303357e-03, 7.27123416e-03,\n",
      "       7.42590015e-04, 6.07657286e-03, 5.86882292e-03, 7.63235056e-03,\n",
      "       3.73575847e-03, 7.12562943e-03, 6.24317623e-03, 6.24283152e-03,\n",
      "       1.24868906e-02, 2.51670659e-05]), 'param_class_weight': masked_array(data=[{0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 3},\n",
      "                   {0: 1, 1: 3}, {0: 1, 1: 3}, {0: 1, 1: 3}, {0: 1, 1: 3},\n",
      "                   {0: 1, 1: 4}, {0: 1, 1: 4}, {0: 1, 1: 4}, {0: 1, 1: 4},\n",
      "                   {0: 1, 1: 4}, {0: 1, 1: 4}],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[10, 10, 20, 20, 40, 40, 10, 10, 20, 20, 40, 40, 10, 10,\n",
      "                   20, 20, 40, 40],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
      "                   50, 100, 50, 100, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_random_state': masked_array(data=[888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}], 'split0_test_score': array([0.53348908, 0.53348141, 0.52348502, 0.51404436, 0.50303086,\n",
      "       0.50073552, 0.57778748, 0.58181538, 0.57217421, 0.57411641,\n",
      "       0.54910308, 0.55278674, 0.57916467, 0.58250722, 0.56998473,\n",
      "       0.57014518, 0.56475041, 0.55974773]), 'split1_test_score': array([0.51827648, 0.51864913, 0.5130202 , 0.50884891, 0.49799406,\n",
      "       0.49989505, 0.54646098, 0.55456551, 0.54125662, 0.53922638,\n",
      "       0.53624604, 0.53419822, 0.55761203, 0.56385767, 0.55059064,\n",
      "       0.55444368, 0.53374831, 0.53843634]), 'split2_test_score': array([0.52472945, 0.52771185, 0.51193575, 0.5245955 , 0.50443721,\n",
      "       0.49734981, 0.55048254, 0.54518135, 0.53854203, 0.5413211 ,\n",
      "       0.52525249, 0.53249064, 0.54588487, 0.5508475 , 0.5424545 ,\n",
      "       0.53967285, 0.53241202, 0.53307879]), 'split3_test_score': array([0.49500141, 0.49796993, 0.48684446, 0.49263649, 0.46940494,\n",
      "       0.46923564, 0.53762749, 0.53606481, 0.52481641, 0.51973934,\n",
      "       0.51510712, 0.51540842, 0.53334731, 0.53613686, 0.52594005,\n",
      "       0.53016581, 0.52772967, 0.52782263]), 'split4_test_score': array([0.53777441, 0.53275027, 0.53022776, 0.52109221, 0.48937778,\n",
      "       0.50189372, 0.56014365, 0.55892932, 0.55054084, 0.55210808,\n",
      "       0.53757333, 0.53832553, 0.55464417, 0.56066046, 0.54657985,\n",
      "       0.55501438, 0.53855035, 0.54048191]), 'mean_test_score': array([0.52185417, 0.52211252, 0.51310264, 0.51224349, 0.49284897,\n",
      "       0.49382195, 0.55450043, 0.55531127, 0.54546602, 0.54530226,\n",
      "       0.53265641, 0.53464191, 0.55413061, 0.55880194, 0.54710995,\n",
      "       0.54988838, 0.53943815, 0.53991348]), 'std_test_score': array([0.0150397 , 0.01318048, 0.01477785, 0.01122562, 0.01285381,\n",
      "       0.01238359, 0.01370843, 0.01542178, 0.01569171, 0.01779215,\n",
      "       0.01157886, 0.01197962, 0.01509322, 0.01528355, 0.0141809 ,\n",
      "       0.01378914, 0.01311738, 0.01085176]), 'rank_test_score': array([14, 13, 15, 16, 18, 17,  3,  2,  7,  8, 12, 11,  4,  1,  6,  5, 10,\n",
      "        9])}\n"
     ]
    }
   ],
   "source": [
    "# random forest + grid search\n",
    "\n",
    "myscorer = make_scorer(matthews_corrcoef)\n",
    "parameters = {\n",
    "    'n_estimators' : [50, 100],\n",
    "    'max_depth': [15],\n",
    "    'criterion' : ['gini'],\n",
    "    'min_samples_leaf': [10, 20, 40,],\n",
    "    'class_weight': [{0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}],\n",
    "    'random_state': [888]\n",
    "}\n",
    "mygridsearch = GridSearchCV(estimator = RandomForestClassifier(),\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888),\n",
    "                            verbose = 2)\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)\n",
    "print(mygridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best score of random foreset is 0.5578066624582119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add column year + one-hot encoding +grid search\n",
    "\n",
    "Secondly, we will **add feature \"year\"** as we mentioned in the feature preprocessing part. We would **not specify customized encoding method** here but just use one-hot encoding to encode all the categorical features.\n",
    "\n",
    "After that, we will carry on elementry grid search again. \n",
    "\n",
    "Results:\n",
    "> Decision Tree: 0.5623514379422441 <br> \n",
    "> Random Forest: **0.5896692297640508**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the module\n",
    "%reset -f\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data = pd.read_csv(\"..\\\\bank-full-add_timestamp.csv\", sep=',', engine=\"python\")\n",
    "\n",
    "y = data['y'].replace({\"yes\":1,\"no\":0})\n",
    "data.drop(columns = ['y', 'timestamp'], inplace = True)\n",
    "\n",
    "data['weekday'] = data['weekday'].astype(str)\n",
    "data['year'] = data['year'].astype(str)\n",
    "data['month'] = data['month'].astype(str)\n",
    "\n",
    "# data.head()\n",
    "\n",
    "number_list = []\n",
    "discrete_list = []\n",
    "for col in data.columns:\n",
    "#     print(col, \":\", data[col].dtype)\n",
    "    if data[col].dtype == \"object\":\n",
    "        discrete_list.append(col)\n",
    "    else:\n",
    "        number_list.append(col)\n",
    "        \n",
    "print(number_list)\n",
    "print(discrete_list)\n",
    "\n",
    "X = pd.get_dummies(data, columns=discrete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight=None, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight=None, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, random_state=888; total time=   0.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 5}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=gini, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=3, random_state=888; total time=   0.0s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=3, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=4, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=5, random_state=888; total time=   0.1s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=10, random_state=888; total time=   0.2s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "[CV] END class_weight={0: 1, 1: 2.125}, criterion=entropy, max_depth=15, random_state=888; total time=   0.3s\n",
      "{'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}\n",
      "0.5623514379422441\n",
      "{'mean_fit_time': array([0.14730806, 0.18114376, 0.19815512, 0.31997013, 0.36047945,\n",
      "       0.14942117, 0.17868161, 0.19635844, 0.31203895, 0.35713377,\n",
      "       0.13364539, 0.16166182, 0.18341713, 0.31914535, 0.40985656,\n",
      "       0.13062019, 0.16257505, 0.19329586, 0.31235223, 0.36376019,\n",
      "       0.13992314, 0.1659544 , 0.18748975, 0.31557827, 0.40977364,\n",
      "       0.14018912, 0.16932688, 0.19783854, 0.30958037, 0.36993432,\n",
      "       0.14008627, 0.16296463, 0.189433  , 0.31498318, 0.36714106,\n",
      "       0.14317122, 0.1689662 , 0.1956574 , 0.30268011, 0.35399494,\n",
      "       0.13350019, 0.16245141, 0.1862102 , 0.31500378, 0.39648695,\n",
      "       0.13758125, 0.16561985, 0.18975277, 0.31903758, 0.37343988]), 'std_fit_time': array([0.0096506 , 0.01357025, 0.00618423, 0.00696872, 0.00759999,\n",
      "       0.01454557, 0.00813488, 0.00716813, 0.00664403, 0.01125554,\n",
      "       0.00783565, 0.01228144, 0.00616066, 0.00397029, 0.00722955,\n",
      "       0.00511388, 0.00524419, 0.00557558, 0.00877929, 0.00597919,\n",
      "       0.00804753, 0.00749012, 0.00731675, 0.00435964, 0.02132528,\n",
      "       0.00241031, 0.00859799, 0.00889906, 0.00746438, 0.01002556,\n",
      "       0.00267038, 0.00539973, 0.00403571, 0.00993841, 0.00938112,\n",
      "       0.00324131, 0.00753479, 0.01336903, 0.01052634, 0.01028194,\n",
      "       0.00926723, 0.0053318 , 0.00444555, 0.00591326, 0.01089384,\n",
      "       0.00387943, 0.00841119, 0.00389837, 0.01231188, 0.00887905]), 'mean_score_time': array([0.01743407, 0.01394844, 0.02290516, 0.01874781, 0.01875587,\n",
      "       0.01561999, 0.0156404 , 0.02826948, 0.01562572, 0.0187469 ,\n",
      "       0.0156291 , 0.0162868 , 0.02038236, 0.01875882, 0.01561522,\n",
      "       0.02228341, 0.01872306, 0.01789927, 0.01563592, 0.01874347,\n",
      "       0.0156157 , 0.01876321, 0.0242332 , 0.01873698, 0.0156177 ,\n",
      "       0.01561351, 0.01563482, 0.02206855, 0.01872597, 0.01875329,\n",
      "       0.01562362, 0.02186408, 0.02123189, 0.01561484, 0.01875372,\n",
      "       0.0156352 , 0.01876154, 0.01655617, 0.0218698 , 0.01875186,\n",
      "       0.01561995, 0.01873159, 0.02259111, 0.0187541 , 0.0156033 ,\n",
      "       0.01876383, 0.01873112, 0.0283618 , 0.01563497, 0.01562185]), 'std_score_time': array([7.37498741e-03, 5.13031740e-03, 4.45096874e-03, 6.24704588e-03,\n",
      "       6.23983310e-03, 2.67203308e-05, 1.20684084e-05, 5.66886052e-03,\n",
      "       1.13603388e-05, 6.25169556e-03, 2.29221331e-05, 1.33065119e-03,\n",
      "       5.81662724e-03, 6.24596208e-03, 2.52957506e-05, 7.34375575e-03,\n",
      "       6.26139855e-03, 4.58017310e-03, 1.01549523e-05, 6.25019602e-03,\n",
      "       1.67620300e-05, 6.24007559e-03, 7.20663671e-03, 6.27487645e-03,\n",
      "       2.22712051e-05, 1.96173148e-05, 3.17769663e-05, 6.48193103e-03,\n",
      "       6.25701976e-03, 6.24254753e-03, 1.82382577e-05, 7.65745384e-03,\n",
      "       6.94114730e-03, 2.96344224e-05, 6.26221171e-03, 2.13255524e-05,\n",
      "       6.25485526e-03, 1.13957898e-03, 7.64014384e-03, 6.26135951e-03,\n",
      "       2.27963074e-05, 6.24169703e-03, 8.61772590e-03, 6.23163809e-03,\n",
      "       1.11777384e-05, 6.24573046e-03, 6.24234938e-03, 3.21482389e-03,\n",
      "       2.25571697e-05, 2.32672104e-05]), 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', None, None, None, None, None,\n",
      "                   None, None, None, None, None, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 5},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}, {0: 1, 1: 2.125}, {0: 1, 1: 2.125},\n",
      "                   {0: 1, 1: 2.125}],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3,\n",
      "                   4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4,\n",
      "                   5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5, 10, 15, 3, 4, 5,\n",
      "                   10, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_random_state': masked_array(data=[888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'gini', 'max_depth': 15, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 4, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 5, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 10, 'random_state': 888}, {'class_weight': {0: 1, 1: 2.125}, 'criterion': 'entropy', 'max_depth': 15, 'random_state': 888}], 'split0_test_score': array([0.45433089, 0.48619792, 0.51942426, 0.53467643, 0.5251398 ,\n",
      "       0.42566442, 0.44833085, 0.49292564, 0.54835819, 0.51185088,\n",
      "       0.43701311, 0.46734025, 0.46372657, 0.49439922, 0.44127213,\n",
      "       0.46487934, 0.43521514, 0.4610638 , 0.53955295, 0.49581249,\n",
      "       0.49515441, 0.49780868, 0.51072844, 0.57811182, 0.51609549,\n",
      "       0.41675619, 0.50072827, 0.52150265, 0.56625872, 0.5279157 ,\n",
      "       0.46568881, 0.52172722, 0.54334017, 0.56012468, 0.53536165,\n",
      "       0.45769393, 0.49403491, 0.54037824, 0.55505635, 0.52403326,\n",
      "       0.49515441, 0.49780868, 0.54537469, 0.57456879, 0.51500992,\n",
      "       0.41675619, 0.49944195, 0.52059139, 0.56717105, 0.51791989]), 'split1_test_score': array([0.41197782, 0.43874529, 0.48120892, 0.55083359, 0.53720907,\n",
      "       0.41197782, 0.43874529, 0.48526325, 0.54340695, 0.50339416,\n",
      "       0.43300393, 0.50233509, 0.50430475, 0.52242007, 0.45542344,\n",
      "       0.43495974, 0.46520797, 0.46923031, 0.51494037, 0.46900836,\n",
      "       0.48462363, 0.5021597 , 0.51328929, 0.56026888, 0.51067719,\n",
      "       0.48243059, 0.48131879, 0.49275908, 0.5655121 , 0.51283496,\n",
      "       0.4691959 , 0.50769752, 0.5190247 , 0.56319411, 0.53508232,\n",
      "       0.44099125, 0.43968925, 0.53085566, 0.56017578, 0.53038207,\n",
      "       0.48462363, 0.4929527 , 0.51918222, 0.5706002 , 0.50337225,\n",
      "       0.48243059, 0.48131879, 0.49470015, 0.56394685, 0.51130478]), 'split2_test_score': array([0.40152323, 0.43522817, 0.481443  , 0.52797285, 0.51740384,\n",
      "       0.40152323, 0.42993812, 0.48016593, 0.51161167, 0.48850131,\n",
      "       0.43402616, 0.50062067, 0.44147061, 0.4981592 , 0.4704773 ,\n",
      "       0.43588712, 0.45736408, 0.39160097, 0.48304732, 0.48065177,\n",
      "       0.47539917, 0.48494691, 0.49932691, 0.54262544, 0.4822923 ,\n",
      "       0.36033121, 0.50008164, 0.46749175, 0.54677747, 0.5171675 ,\n",
      "       0.45604133, 0.49342238, 0.51291959, 0.52325049, 0.49789862,\n",
      "       0.41774869, 0.43736647, 0.52066237, 0.54151149, 0.49346135,\n",
      "       0.47539917, 0.48494691, 0.5221591 , 0.54822787, 0.50003184,\n",
      "       0.46958032, 0.47833794, 0.49597811, 0.5638832 , 0.50810315]), 'split3_test_score': array([0.44472998, 0.48348656, 0.48000064, 0.51665916, 0.50154481,\n",
      "       0.40013405, 0.44177933, 0.4542968 , 0.52617719, 0.4929855 ,\n",
      "       0.39128254, 0.48274114, 0.44975552, 0.50845801, 0.48144575,\n",
      "       0.40614277, 0.44329091, 0.41940979, 0.4866498 , 0.46667184,\n",
      "       0.44523769, 0.46997808, 0.51904341, 0.53611137, 0.50517522,\n",
      "       0.35543787, 0.47523248, 0.45782264, 0.53860824, 0.51805562,\n",
      "       0.45513874, 0.50546921, 0.52318453, 0.55362803, 0.51048416,\n",
      "       0.44472998, 0.48693616, 0.51112492, 0.54344989, 0.49933946,\n",
      "       0.44523769, 0.46997808, 0.51904341, 0.54531516, 0.50427854,\n",
      "       0.35543787, 0.47523248, 0.50462293, 0.55138098, 0.51542566]), 'split4_test_score': array([0.44511392, 0.4739047 , 0.52586377, 0.5328255 , 0.52247374,\n",
      "       0.42692974, 0.45749671, 0.49817461, 0.54746113, 0.51852156,\n",
      "       0.43683085, 0.43437988, 0.42764552, 0.51527936, 0.49607263,\n",
      "       0.42068993, 0.47182927, 0.43576967, 0.51346239, 0.48903848,\n",
      "       0.45878033, 0.46136462, 0.49822449, 0.56693341, 0.51817032,\n",
      "       0.39634819, 0.48946047, 0.49839658, 0.5553901 , 0.52457898,\n",
      "       0.47054112, 0.51980997, 0.53355298, 0.55921004, 0.51867046,\n",
      "       0.44015636, 0.46318764, 0.51393377, 0.56875301, 0.51357533,\n",
      "       0.48026817, 0.48221331, 0.53651654, 0.56588989, 0.53026204,\n",
      "       0.39634819, 0.51618084, 0.49839658, 0.56537511, 0.53393187]), 'mean_test_score': array([0.43153517, 0.46351253, 0.49758812, 0.53259351, 0.52075425,\n",
      "       0.41324585, 0.44325806, 0.48216525, 0.53540303, 0.50305068,\n",
      "       0.42643132, 0.47748341, 0.45738059, 0.50774317, 0.46893825,\n",
      "       0.43251178, 0.45458147, 0.43541491, 0.50753057, 0.48023659,\n",
      "       0.47183905, 0.4832516 , 0.50812251, 0.55681019, 0.50648211,\n",
      "       0.40226081, 0.48936433, 0.48759454, 0.55450933, 0.52011055,\n",
      "       0.46332118, 0.50962526, 0.52640439, 0.55188147, 0.51949944,\n",
      "       0.44026404, 0.46424289, 0.52339099, 0.5537893 , 0.51215829,\n",
      "       0.47613661, 0.48557994, 0.52845519, 0.56092038, 0.51059092,\n",
      "       0.42411063, 0.4901024 , 0.50285783, 0.56235144, 0.51733707]), 'std_test_score': array([0.02079104, 0.02206811, 0.02056498, 0.01106659, 0.01160327,\n",
      "       0.01142293, 0.00925683, 0.01524684, 0.01434184, 0.01122409,\n",
      "       0.01764337, 0.02506543, 0.02622057, 0.01041758, 0.01919972,\n",
      "       0.01949423, 0.0135697 , 0.02820389, 0.02074107, 0.01122791,\n",
      "       0.01787673, 0.0156686 , 0.00810044, 0.01547805, 0.01291112,\n",
      "       0.04609283, 0.01008413, 0.0227315 , 0.01070057, 0.00541675,\n",
      "       0.00651451, 0.01033158, 0.01081286, 0.01464526, 0.01444295,\n",
      "       0.01289362, 0.02336187, 0.01087777, 0.01023673, 0.01406433,\n",
      "       0.01676939, 0.00958178, 0.01063452, 0.01191047, 0.01104473,\n",
      "       0.0469244 , 0.01551761, 0.00950132, 0.00561451, 0.00895583]), 'rank_test_score': array([46, 38, 25,  8, 12, 49, 42, 31,  7, 23, 47, 33, 40, 20, 36, 45, 41,\n",
      "       44, 21, 32, 35, 30, 19,  3, 22, 50, 27, 28,  4, 13, 39, 18, 10,  6,\n",
      "       14, 43, 37, 11,  5, 16, 34, 29,  9,  2, 17, 48, 26, 24,  1, 15])}\n"
     ]
    }
   ],
   "source": [
    "# decision tree + grid search\n",
    "\n",
    "myscorer = make_scorer(matthews_corrcoef)\n",
    "parameters = {'criterion':['gini','entropy'],\\\n",
    "              'max_depth':[3, 4, 5, 10, 15],\\\n",
    "              'class_weight':['balanced', None, {0: 1, 1: 2}, {0: 1, 1: 5},{0: 1, 1: 2.125}],\n",
    "              'random_state': [888]}\n",
    "mygridsearch = GridSearchCV(estimator = DecisionTreeClassifier(),\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888),\n",
    "                            verbose = 2)\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)\n",
    "print(mygridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best score of decision tree is 0.5623514379422441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   2.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.0s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   4.1s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.7s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.9s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 2}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.8s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.4s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.2s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.2s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.2s\n",
      "[CV] END class_weight={0: 1, 1: 3}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.9s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=10, n_estimators=100, random_state=888; total time=   3.8s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.7s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=50, random_state=888; total time=   1.6s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=20, n_estimators=100, random_state=888; total time=   3.3s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=50, random_state=888; total time=   1.5s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.1s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.0s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.1s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.1s\n",
      "[CV] END class_weight={0: 1, 1: 4}, criterion=gini, max_depth=15, min_samples_leaf=40, n_estimators=100, random_state=888; total time=   3.1s\n",
      "{'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}\n",
      "0.5896692297640508\n",
      "{'mean_fit_time': array([1.97005873, 3.91377058, 1.88318033, 3.65429492, 1.8422194 ,\n",
      "       3.37673278, 1.81393871, 3.48182025, 1.68569269, 3.31974363,\n",
      "       1.60659385, 3.19344716, 1.74505262, 3.70279951, 1.70972309,\n",
      "       3.27333059, 1.55528789, 3.06012111]), 'std_fit_time': array([0.07112808, 0.09740455, 0.04330005, 0.06392667, 0.02640994,\n",
      "       0.09836025, 0.00812008, 0.0631392 , 0.00888505, 0.04067   ,\n",
      "       0.04584539, 0.0407824 , 0.01320786, 0.14927712, 0.02542737,\n",
      "       0.01762869, 0.00961684, 0.02377837]), 'mean_score_time': array([0.08414016, 0.1575264 , 0.08914075, 0.16511464, 0.09170446,\n",
      "       0.14294319, 0.08556099, 0.14531522, 0.07657051, 0.14059472,\n",
      "       0.07192302, 0.13177772, 0.0812324 , 0.16721706, 0.07811885,\n",
      "       0.14220624, 0.07498937, 0.12810397]), 'std_score_time': array([6.30027543e-03, 1.34540615e-02, 1.08106218e-02, 1.13251228e-02,\n",
      "       9.60739592e-03, 9.03400067e-03, 1.94841331e-03, 6.25646218e-03,\n",
      "       7.66931266e-03, 1.62096582e-05, 7.73906256e-03, 5.73588036e-03,\n",
      "       6.24665811e-03, 1.69222485e-02, 2.22578269e-05, 1.25579978e-02,\n",
      "       6.25077713e-03, 6.25707490e-03]), 'param_class_weight': masked_array(data=[{0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 2},\n",
      "                   {0: 1, 1: 2}, {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 3},\n",
      "                   {0: 1, 1: 3}, {0: 1, 1: 3}, {0: 1, 1: 3}, {0: 1, 1: 3},\n",
      "                   {0: 1, 1: 4}, {0: 1, 1: 4}, {0: 1, 1: 4}, {0: 1, 1: 4},\n",
      "                   {0: 1, 1: 4}, {0: 1, 1: 4}],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[10, 10, 20, 20, 40, 40, 10, 10, 20, 20, 40, 40, 10, 10,\n",
      "                   20, 20, 40, 40],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
      "                   50, 100, 50, 100, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_random_state': masked_array(data=[888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888,\n",
      "                   888, 888, 888, 888, 888, 888, 888],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 2}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 20, 'n_estimators': 100, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 50, 'random_state': 888}, {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 40, 'n_estimators': 100, 'random_state': 888}], 'split0_test_score': array([0.54529665, 0.55471177, 0.5204909 , 0.53388859, 0.51238668,\n",
      "       0.52273826, 0.58390142, 0.58714867, 0.56867891, 0.57393106,\n",
      "       0.56461054, 0.56783423, 0.59142171, 0.60058942, 0.58677837,\n",
      "       0.59327614, 0.55774563, 0.57123206]), 'split1_test_score': array([0.53222861, 0.54052472, 0.5241742 , 0.53186833, 0.49855556,\n",
      "       0.50989088, 0.58279846, 0.59236284, 0.57137314, 0.58171122,\n",
      "       0.55921982, 0.56934153, 0.58611284, 0.59402986, 0.56707326,\n",
      "       0.57843747, 0.5589305 , 0.57297534]), 'split2_test_score': array([0.53701129, 0.55261259, 0.50641297, 0.53174579, 0.50659787,\n",
      "       0.51923754, 0.5774259 , 0.58789788, 0.56331518, 0.57325806,\n",
      "       0.57552957, 0.57278515, 0.58536094, 0.58806472, 0.57497291,\n",
      "       0.57546922, 0.55865284, 0.5697273 ]), 'split3_test_score': array([0.5348268 , 0.54747225, 0.50847795, 0.5230726 , 0.48086047,\n",
      "       0.50853359, 0.57164987, 0.57268604, 0.56570395, 0.56824048,\n",
      "       0.55356707, 0.57022885, 0.56068748, 0.57093972, 0.56898442,\n",
      "       0.57258472, 0.5573815 , 0.55995241]), 'split4_test_score': array([0.53007845, 0.55371391, 0.52406031, 0.5481086 , 0.50825507,\n",
      "       0.51601018, 0.58852008, 0.59672915, 0.57804583, 0.57529782,\n",
      "       0.55581212, 0.56571353, 0.59048089, 0.59472242, 0.57624889,\n",
      "       0.58329827, 0.56068952, 0.56241143]), 'mean_test_score': array([0.53588836, 0.54980705, 0.51672327, 0.53373678, 0.50133113,\n",
      "       0.51528209, 0.58085915, 0.58736491, 0.5694234 , 0.57448773,\n",
      "       0.56174782, 0.56918066, 0.58281277, 0.58966923, 0.57481157,\n",
      "       0.58061317, 0.55868   , 0.56725971]), 'std_test_score': array([0.00525457, 0.00526885, 0.00771791, 0.00809632, 0.01117726,\n",
      "       0.00541069, 0.0058018 , 0.00810516, 0.00509601, 0.00432863,\n",
      "       0.00783173, 0.00236435, 0.01131217, 0.01017024, 0.00691568,\n",
      "       0.00725549, 0.00115419, 0.00512717]), 'rank_test_score': array([14, 13, 16, 15, 18, 17,  4,  2,  8,  7, 11,  9,  3,  1,  6,  5, 12,\n",
      "       10])}\n"
     ]
    }
   ],
   "source": [
    "# random forest + grid search\n",
    "\n",
    "myscorer = make_scorer(matthews_corrcoef)\n",
    "parameters = {\n",
    "    'n_estimators' : [50, 100],\n",
    "    'max_depth': [15],\n",
    "    'criterion' : ['gini'],\n",
    "    'min_samples_leaf': [10, 20, 40,],\n",
    "    'class_weight': [{0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}],\n",
    "    'random_state': [888]\n",
    "}\n",
    "mygridsearch = GridSearchCV(estimator = RandomForestClassifier(),\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888),\n",
    "                            verbose = 2)\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)\n",
    "print(mygridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best score of random foreset is 0.5896692297640508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add column year + one-hot encoding + SMOTE + grid search\n",
    "\n",
    "In the above test, we decline to modify \"class_weight\" inside the algorithm. Considering the inbalanced label, We will try to adopt resample policy here. \n",
    "\n",
    "Results:\n",
    "> Decision Tree: 0.510029414063708 <br> \n",
    "> Random Forest: **0.5348282104486837**\n",
    "\n",
    "Besides the score, we can also notice that the training time of involving SMOTE method is much longer than single model, but end up with worst score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the module\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "data=pd.read_csv(\"..\\\\bank-full.csv\", sep=';', engine=\"python\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown = 'ignore', sparse = True)\n",
    "y = data['y'].replace({\"yes\":1,\"no\":0})\n",
    "data.drop(columns = ['y'], inplace = True)\n",
    "\n",
    "integer_list = []\n",
    "discrete_list = []\n",
    "for col in data.columns:\n",
    "#     print(col, \":\", data[col].dtype)    \n",
    "    if data[col].dtype == \"object\":\n",
    "        discrete_list.append(col)\n",
    "    else:\n",
    "        integer_list.append(col)\n",
    "        data[col] = data[col].astype(float)\n",
    "X = pd.get_dummies(data, columns=discrete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  24.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  24.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.1s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.1s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.1s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.1s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  12.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.3s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.0s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.3s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.4s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.4s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=5, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.0s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.2s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  15.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  17.1s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.4s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.4s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=10, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  21.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  22.1s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.1s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  16.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__max_depth=15, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  11.9s\n",
      "{'classification__class_weight': {0: 1, 1: 2}, 'classification__criterion': 'gini', 'classification__max_depth': 10, 'classification__random_state': 888, 'sampling__sampling_strategy': 0.3}\n",
      "0.510029414063708\n"
     ]
    }
   ],
   "source": [
    "# grid search + imbpipeline + SMOTENC + decision tree\n",
    "def mcc_calculate(y_true, y_predicted):\n",
    "    conf_matrix = confusion_matrix(y_true, y_predicted)\n",
    "#     print(y_true.value_counts()[0], y_true.value_counts()[1])\n",
    "    TP = conf_matrix[0][0]\n",
    "    FN = conf_matrix[0][1]\n",
    "    FP = conf_matrix[1][0]\n",
    "    TN = conf_matrix[1][1]\n",
    "    if TP + FP == 0  or TP + FN == 0 or TN + FP == 0 or TN + FN == 0:\n",
    "#         print(conf_matrix)\n",
    "        return 0\n",
    "    return float(TP * TN - FP * FN ) / np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN))\n",
    "\n",
    "model = imbpipeline([\n",
    "        ('sampling', SMOTENC(categorical_features = [data.dtypes==object])),\n",
    "        ('classification', DecisionTreeClassifier())\n",
    "    ])\n",
    "## imbpipeline would not resammple the test set.\n",
    "\n",
    "myscorer = make_scorer(mcc_calculate)\n",
    "parameters = {\n",
    "    'sampling__sampling_strategy': [0.5, 0.4, 0.3],\n",
    "    'classification__criterion' :['gini'],\n",
    "    'classification__class_weight':[{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 2, 1: 1}],\n",
    "    'classification__random_state':[888],\n",
    "    'classification__max_depth':[5, 10, 15]\n",
    "}\n",
    "\n",
    "mygridsearch = GridSearchCV(estimator = model,\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888),\n",
    "                            verbose = 2)\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best result of decision tree is 0.510029414063708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  23.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  31.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  30.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  16.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  16.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  15.3s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  14.9s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  19.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  19.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  19.4s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  19.6s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  19.5s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  25.1s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.0s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  31.2s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  30.8s\n",
      "[CV] END classification__class_weight={0: 1, 1: 2}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  30.3s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  19.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.3; total time=  17.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.7s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.8s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.4; total time=  22.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  28.6s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.9s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.5s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  31.1s\n",
      "[CV] END classification__class_weight={0: 2, 1: 1}, classification__criterion=gini, classification__random_state=888, sampling__sampling_strategy=0.5; total time=  29.4s\n",
      "{'classification__class_weight': {0: 2, 1: 1}, 'classification__criterion': 'gini', 'classification__random_state': 888, 'sampling__sampling_strategy': 0.5}\n",
      "0.5348282104486837\n"
     ]
    }
   ],
   "source": [
    "# grid search + imbpipeline + SMOTENC + random forest\n",
    "def mcc_calculate(y_true, y_predicted):\n",
    "    conf_matrix = confusion_matrix(y_true, y_predicted)\n",
    "#     print(y_true.value_counts()[0], y_true.value_counts()[1])\n",
    "    TP = conf_matrix[0][0]\n",
    "    FN = conf_matrix[0][1]\n",
    "    FP = conf_matrix[1][0]\n",
    "    TN = conf_matrix[1][1]\n",
    "    if TP + FP == 0  or TP + FN == 0 or TN + FP == 0 or TN + FN == 0:\n",
    "#         print(conf_matrix)\n",
    "        return 0\n",
    "    return float(TP * TN - FP * FN ) / np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN))\n",
    "\n",
    "model = imbpipeline([\n",
    "        ('sampling', SMOTENC(categorical_features = [data.dtypes==object])),\n",
    "        ('classification', RandomForestClassifier())\n",
    "    ])\n",
    "## imbpipeline would not resammple the test set.\n",
    "\n",
    "myscorer = make_scorer(mcc_calculate)\n",
    "parameters = {\n",
    "    'sampling__sampling_strategy': [0.3, 0.4, 0.5],\n",
    "    'classification__criterion' :['gini'],\n",
    "    'classification__class_weight':[{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 2, 1: 1}],\n",
    "    'classification__random_state':[888]\n",
    "}\n",
    "\n",
    "mygridsearch = GridSearchCV(estimator = model,\\\n",
    "                            param_grid = parameters,\\\n",
    "                            scoring = myscorer,\\\n",
    "                            cv = KFold(n_splits=5, shuffle=True, random_state = 888),\n",
    "                            verbose = 2)\n",
    "mygridsearch.fit(X, y)\n",
    "print(mygridsearch.best_params_)\n",
    "print(mygridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best result of random forest is 0.5348282104486837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate cross term by duration + backward selection + grid search \n",
    "\n",
    "This section we will use duration, which seems quite important in our model, to generate a series of new feature, by .\n",
    "\n",
    "And then we will use the feature importance inside decision tree and random forest to repeatedly eliminate some of these feature.\n",
    "\n",
    "Results:\n",
    "> Decision Tree: 0.510029414063708 <br> \n",
    "> Random Forest: **0.5348282104486837**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
      "Index(['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
      "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
      "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
      "       'marital_divorced', 'marital_married', 'marital_single',\n",
      "       'education_primary', 'education_secondary', 'education_tertiary',\n",
      "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
      "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
      "       'contact_telephone', 'contact_unknown', 'month_1', 'month_10',\n",
      "       'month_11', 'month_12', 'month_2', 'month_3', 'month_4', 'month_5',\n",
      "       'month_6', 'month_7', 'month_8', 'month_9', 'poutcome_failure',\n",
      "       'poutcome_other', 'poutcome_success', 'poutcome_unknown', 'year_2008',\n",
      "       'year_2009', 'year_2010', 'weekday_0', 'weekday_1', 'weekday_2',\n",
      "       'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the module\n",
    "%reset -f\n",
    "from copy import deepcopy\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data = pd.read_csv(\"..\\\\bank-full-add_timestamp.csv\", sep=',', engine=\"python\")\n",
    "\n",
    "y = data['y'].replace({\"yes\":1,\"no\":0})\n",
    "data.drop(columns = ['y', 'day', 'timestamp'], inplace = True)\n",
    "data['weekday'] = data['weekday'].astype(str)\n",
    "data['year'] = data['year'].astype(str)\n",
    "data['month'] = data['month'].astype(str)\n",
    "\n",
    "# data.head()\n",
    "\n",
    "number_list = []\n",
    "discrete_list = []\n",
    "for col in data.columns:\n",
    "#     print(col, \":\", data[col].dtype)\n",
    "    if data[col].dtype == \"object\":\n",
    "        discrete_list.append(col)\n",
    "    else:\n",
    "        number_list.append(col)\n",
    "        \n",
    "print(number_list)\n",
    "print(discrete_list)\n",
    "\n",
    "X = pd.get_dummies(data, columns = discrete_list)\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "for col in X.columns.drop(['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']):\n",
    "    for num_col in ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']:\n",
    "        X[num_col + \"_\" + col] = X[num_col] * X[col]\n",
    "X[\"duration\" + \"_\" + \"age\"] = X['age'] * X['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 385)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 385\n",
      "---number of yes in train 4219, in test 1070, in predict 1533, mcc score is 0.5590\n",
      "---number of yes in train 4230, in test 1059, in predict 1474, mcc score is 0.5432\n",
      "---number of yes in train 4251, in test 1038, in predict 1452, mcc score is 0.5370\n",
      "---number of yes in train 4249, in test 1040, in predict 1495, mcc score is 0.5403\n",
      "---number of yes in train 4207, in test 1082, in predict 1377, mcc score is 0.5332\n",
      "---mean score 0.5425\n",
      "Feature Number: 365\n",
      "---number of yes in train 4219, in test 1070, in predict 1529, mcc score is 0.5609\n",
      "---number of yes in train 4230, in test 1059, in predict 1479, mcc score is 0.5391\n",
      "---number of yes in train 4251, in test 1038, in predict 1453, mcc score is 0.5349\n",
      "---number of yes in train 4249, in test 1040, in predict 1479, mcc score is 0.5388\n",
      "---number of yes in train 4207, in test 1082, in predict 1391, mcc score is 0.5341\n",
      "---mean score 0.5416\n",
      "Feature Number: 345\n",
      "---number of yes in train 4219, in test 1070, in predict 1537, mcc score is 0.5589\n",
      "---number of yes in train 4230, in test 1059, in predict 1459, mcc score is 0.5424\n",
      "---number of yes in train 4251, in test 1038, in predict 1452, mcc score is 0.5380\n",
      "---number of yes in train 4249, in test 1040, in predict 1483, mcc score is 0.5434\n",
      "---number of yes in train 4207, in test 1082, in predict 1408, mcc score is 0.5446\n",
      "---mean score 0.5454\n",
      "Feature Number: 325\n",
      "---number of yes in train 4219, in test 1070, in predict 1540, mcc score is 0.5609\n",
      "---number of yes in train 4230, in test 1059, in predict 1451, mcc score is 0.5445\n",
      "---number of yes in train 4251, in test 1038, in predict 1499, mcc score is 0.5438\n",
      "---number of yes in train 4249, in test 1040, in predict 1476, mcc score is 0.5405\n",
      "---number of yes in train 4207, in test 1082, in predict 1406, mcc score is 0.5376\n",
      "---mean score 0.5454\n",
      "Feature Number: 305\n",
      "---number of yes in train 4219, in test 1070, in predict 1521, mcc score is 0.5630\n",
      "---number of yes in train 4230, in test 1059, in predict 1454, mcc score is 0.5418\n",
      "---number of yes in train 4251, in test 1038, in predict 1453, mcc score is 0.5358\n",
      "---number of yes in train 4249, in test 1040, in predict 1474, mcc score is 0.5400\n",
      "---number of yes in train 4207, in test 1082, in predict 1413, mcc score is 0.5423\n",
      "---mean score 0.5446\n",
      "Feature Number: 285\n",
      "---number of yes in train 4219, in test 1070, in predict 1526, mcc score is 0.5635\n",
      "---number of yes in train 4230, in test 1059, in predict 1470, mcc score is 0.5358\n",
      "---number of yes in train 4251, in test 1038, in predict 1454, mcc score is 0.5384\n",
      "---number of yes in train 4249, in test 1040, in predict 1476, mcc score is 0.5386\n",
      "---number of yes in train 4207, in test 1082, in predict 1415, mcc score is 0.5399\n",
      "---mean score 0.5432\n",
      "Feature Number: 265\n",
      "---number of yes in train 4219, in test 1070, in predict 1526, mcc score is 0.5608\n",
      "---number of yes in train 4230, in test 1059, in predict 1468, mcc score is 0.5373\n",
      "---number of yes in train 4251, in test 1038, in predict 1445, mcc score is 0.5351\n",
      "---number of yes in train 4249, in test 1040, in predict 1470, mcc score is 0.5382\n",
      "---number of yes in train 4207, in test 1082, in predict 1437, mcc score is 0.5481\n",
      "---mean score 0.5439\n",
      "Feature Number: 245\n",
      "---number of yes in train 4219, in test 1070, in predict 1525, mcc score is 0.5628\n",
      "---number of yes in train 4230, in test 1059, in predict 1455, mcc score is 0.5415\n",
      "---number of yes in train 4251, in test 1038, in predict 1450, mcc score is 0.5404\n",
      "---number of yes in train 4249, in test 1040, in predict 1538, mcc score is 0.5334\n",
      "---number of yes in train 4207, in test 1082, in predict 1467, mcc score is 0.5457\n",
      "---mean score 0.5448\n",
      "Feature Number: 225\n",
      "---number of yes in train 4219, in test 1070, in predict 1526, mcc score is 0.5608\n",
      "---number of yes in train 4230, in test 1059, in predict 1465, mcc score is 0.5362\n",
      "---number of yes in train 4251, in test 1038, in predict 1450, mcc score is 0.5451\n",
      "---number of yes in train 4249, in test 1040, in predict 1508, mcc score is 0.5306\n",
      "---number of yes in train 4207, in test 1082, in predict 1457, mcc score is 0.5437\n",
      "---mean score 0.5433\n",
      "Feature Number: 205\n",
      "---number of yes in train 4219, in test 1070, in predict 1537, mcc score is 0.5634\n",
      "---number of yes in train 4230, in test 1059, in predict 1482, mcc score is 0.5365\n",
      "---number of yes in train 4251, in test 1038, in predict 1379, mcc score is 0.5391\n",
      "---number of yes in train 4249, in test 1040, in predict 1514, mcc score is 0.5300\n",
      "---number of yes in train 4207, in test 1082, in predict 1439, mcc score is 0.5363\n",
      "---mean score 0.5411\n",
      "Feature Number: 185\n",
      "---number of yes in train 4219, in test 1070, in predict 1530, mcc score is 0.5671\n",
      "---number of yes in train 4230, in test 1059, in predict 1480, mcc score is 0.5388\n",
      "---number of yes in train 4251, in test 1038, in predict 1385, mcc score is 0.5337\n",
      "---number of yes in train 4249, in test 1040, in predict 1440, mcc score is 0.5337\n",
      "---number of yes in train 4207, in test 1082, in predict 1401, mcc score is 0.5380\n",
      "---mean score 0.5423\n",
      "Feature Number: 175\n",
      "---number of yes in train 4219, in test 1070, in predict 1538, mcc score is 0.5668\n",
      "---number of yes in train 4230, in test 1059, in predict 1466, mcc score is 0.5396\n",
      "---number of yes in train 4251, in test 1038, in predict 1378, mcc score is 0.5327\n",
      "---number of yes in train 4249, in test 1040, in predict 1458, mcc score is 0.5366\n",
      "---number of yes in train 4207, in test 1082, in predict 1413, mcc score is 0.5433\n",
      "---mean score 0.5438\n",
      "Feature Number: 165\n",
      "---number of yes in train 4219, in test 1070, in predict 1531, mcc score is 0.5668\n",
      "---number of yes in train 4230, in test 1059, in predict 1480, mcc score is 0.5398\n",
      "---number of yes in train 4251, in test 1038, in predict 1409, mcc score is 0.5378\n",
      "---number of yes in train 4249, in test 1040, in predict 1458, mcc score is 0.5291\n",
      "---number of yes in train 4207, in test 1082, in predict 1417, mcc score is 0.5431\n",
      "---mean score 0.5433\n",
      "Feature Number: 155\n",
      "---number of yes in train 4219, in test 1070, in predict 1538, mcc score is 0.5650\n",
      "---number of yes in train 4230, in test 1059, in predict 1481, mcc score is 0.5395\n",
      "---number of yes in train 4251, in test 1038, in predict 1413, mcc score is 0.5396\n",
      "---number of yes in train 4249, in test 1040, in predict 1463, mcc score is 0.5325\n",
      "---number of yes in train 4207, in test 1082, in predict 1414, mcc score is 0.5430\n",
      "---mean score 0.5439\n",
      "Feature Number: 145\n",
      "---number of yes in train 4219, in test 1070, in predict 1539, mcc score is 0.5684\n",
      "---number of yes in train 4230, in test 1059, in predict 1478, mcc score is 0.5403\n",
      "---number of yes in train 4251, in test 1038, in predict 1408, mcc score is 0.5352\n",
      "---number of yes in train 4249, in test 1040, in predict 1451, mcc score is 0.5290\n",
      "---number of yes in train 4207, in test 1082, in predict 1417, mcc score is 0.5431\n",
      "---mean score 0.5432\n",
      "Feature Number: 140\n",
      "---number of yes in train 4219, in test 1070, in predict 1538, mcc score is 0.5668\n",
      "---number of yes in train 4230, in test 1059, in predict 1467, mcc score is 0.5394\n",
      "---number of yes in train 4251, in test 1038, in predict 1410, mcc score is 0.5366\n",
      "---number of yes in train 4249, in test 1040, in predict 1446, mcc score is 0.5303\n",
      "---number of yes in train 4207, in test 1082, in predict 1404, mcc score is 0.5382\n",
      "---mean score 0.5422\n",
      "Feature Number: 135\n",
      "---number of yes in train 4219, in test 1070, in predict 1536, mcc score is 0.5655\n",
      "---number of yes in train 4230, in test 1059, in predict 1480, mcc score is 0.5407\n",
      "---number of yes in train 4251, in test 1038, in predict 1414, mcc score is 0.5422\n",
      "---number of yes in train 4249, in test 1040, in predict 1443, mcc score is 0.5310\n",
      "---number of yes in train 4207, in test 1082, in predict 1405, mcc score is 0.5426\n",
      "---mean score 0.5444\n",
      "Feature Number: 130\n",
      "---number of yes in train 4219, in test 1070, in predict 1548, mcc score is 0.5670\n",
      "---number of yes in train 4230, in test 1059, in predict 1482, mcc score is 0.5365\n",
      "---number of yes in train 4251, in test 1038, in predict 1415, mcc score is 0.5410\n",
      "---number of yes in train 4249, in test 1040, in predict 1455, mcc score is 0.5346\n",
      "---number of yes in train 4207, in test 1082, in predict 1421, mcc score is 0.5477\n",
      "---mean score 0.5453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 125\n",
      "---number of yes in train 4219, in test 1070, in predict 1549, mcc score is 0.5650\n",
      "---number of yes in train 4230, in test 1059, in predict 1471, mcc score is 0.5411\n",
      "---number of yes in train 4251, in test 1038, in predict 1399, mcc score is 0.5376\n",
      "---number of yes in train 4249, in test 1040, in predict 1445, mcc score is 0.5352\n",
      "---number of yes in train 4207, in test 1082, in predict 1414, mcc score is 0.5420\n",
      "---mean score 0.5442\n",
      "Feature Number: 120\n",
      "---number of yes in train 4219, in test 1070, in predict 1577, mcc score is 0.5670\n",
      "---number of yes in train 4230, in test 1059, in predict 1485, mcc score is 0.5366\n",
      "---number of yes in train 4251, in test 1038, in predict 1424, mcc score is 0.5396\n",
      "---number of yes in train 4249, in test 1040, in predict 1445, mcc score is 0.5362\n",
      "---number of yes in train 4207, in test 1082, in predict 1423, mcc score is 0.5490\n",
      "---mean score 0.5457\n",
      "Feature Number: 115\n",
      "---number of yes in train 4219, in test 1070, in predict 1583, mcc score is 0.5682\n",
      "---number of yes in train 4230, in test 1059, in predict 1479, mcc score is 0.5419\n",
      "---number of yes in train 4251, in test 1038, in predict 1425, mcc score is 0.5384\n",
      "---number of yes in train 4249, in test 1040, in predict 1446, mcc score is 0.5388\n",
      "---number of yes in train 4207, in test 1082, in predict 1407, mcc score is 0.5383\n",
      "---mean score 0.5451\n",
      "Feature Number: 110\n",
      "---number of yes in train 4219, in test 1070, in predict 1570, mcc score is 0.5688\n",
      "---number of yes in train 4230, in test 1059, in predict 1492, mcc score is 0.5404\n",
      "---number of yes in train 4251, in test 1038, in predict 1419, mcc score is 0.5457\n",
      "---number of yes in train 4249, in test 1040, in predict 1449, mcc score is 0.5399\n",
      "---number of yes in train 4207, in test 1082, in predict 1420, mcc score is 0.5442\n",
      "---mean score 0.5478\n",
      "Feature Number: 105\n",
      "---number of yes in train 4219, in test 1070, in predict 1572, mcc score is 0.5719\n",
      "---number of yes in train 4230, in test 1059, in predict 1469, mcc score is 0.5407\n",
      "---number of yes in train 4251, in test 1038, in predict 1427, mcc score is 0.5474\n",
      "---number of yes in train 4249, in test 1040, in predict 1437, mcc score is 0.5316\n",
      "---number of yes in train 4207, in test 1082, in predict 1415, mcc score is 0.5446\n",
      "---mean score 0.5472\n",
      "Feature Number: 100\n",
      "---number of yes in train 4219, in test 1070, in predict 1572, mcc score is 0.5692\n",
      "---number of yes in train 4230, in test 1059, in predict 1457, mcc score is 0.5438\n",
      "---number of yes in train 4251, in test 1038, in predict 1422, mcc score is 0.5439\n",
      "---number of yes in train 4249, in test 1040, in predict 1446, mcc score is 0.5378\n",
      "---number of yes in train 4207, in test 1082, in predict 1410, mcc score is 0.5422\n",
      "---mean score 0.5474\n",
      "Feature Number: 95\n",
      "---number of yes in train 4219, in test 1070, in predict 1546, mcc score is 0.5694\n",
      "---number of yes in train 4230, in test 1059, in predict 1446, mcc score is 0.5392\n",
      "---number of yes in train 4251, in test 1038, in predict 1415, mcc score is 0.5401\n",
      "---number of yes in train 4249, in test 1040, in predict 1460, mcc score is 0.5389\n",
      "---number of yes in train 4207, in test 1082, in predict 1414, mcc score is 0.5449\n",
      "---mean score 0.5465\n",
      "Feature Number: 90\n",
      "---number of yes in train 4219, in test 1070, in predict 1555, mcc score is 0.5707\n",
      "---number of yes in train 4230, in test 1059, in predict 1440, mcc score is 0.5427\n",
      "---number of yes in train 4251, in test 1038, in predict 1410, mcc score is 0.5462\n",
      "---number of yes in train 4249, in test 1040, in predict 1471, mcc score is 0.5408\n",
      "---number of yes in train 4207, in test 1082, in predict 1413, mcc score is 0.5433\n",
      "---mean score 0.5487\n",
      "Feature Number: 85\n",
      "---number of yes in train 4219, in test 1070, in predict 1555, mcc score is 0.5743\n",
      "---number of yes in train 4230, in test 1059, in predict 1379, mcc score is 0.5362\n",
      "---number of yes in train 4251, in test 1038, in predict 1435, mcc score is 0.5519\n",
      "---number of yes in train 4249, in test 1040, in predict 1480, mcc score is 0.5432\n",
      "---number of yes in train 4207, in test 1082, in predict 1411, mcc score is 0.5429\n",
      "---mean score 0.5497\n",
      "Feature Number: 80\n",
      "---number of yes in train 4219, in test 1070, in predict 1542, mcc score is 0.5704\n",
      "---number of yes in train 4230, in test 1059, in predict 1374, mcc score is 0.5443\n",
      "---number of yes in train 4251, in test 1038, in predict 1440, mcc score is 0.5496\n",
      "---number of yes in train 4249, in test 1040, in predict 1451, mcc score is 0.5441\n",
      "---number of yes in train 4207, in test 1082, in predict 1409, mcc score is 0.5453\n",
      "---mean score 0.5507\n",
      "Feature Number: 75\n",
      "---number of yes in train 4219, in test 1070, in predict 1543, mcc score is 0.5683\n",
      "---number of yes in train 4230, in test 1059, in predict 1411, mcc score is 0.5466\n",
      "---number of yes in train 4251, in test 1038, in predict 1416, mcc score is 0.5474\n",
      "---number of yes in train 4249, in test 1040, in predict 1462, mcc score is 0.5431\n",
      "---number of yes in train 4207, in test 1082, in predict 1378, mcc score is 0.5471\n",
      "---mean score 0.5505\n",
      "Feature Number: 70\n",
      "---number of yes in train 4219, in test 1070, in predict 1565, mcc score is 0.5664\n",
      "---number of yes in train 4230, in test 1059, in predict 1415, mcc score is 0.5465\n",
      "---number of yes in train 4251, in test 1038, in predict 1415, mcc score is 0.5458\n",
      "---number of yes in train 4249, in test 1040, in predict 1516, mcc score is 0.5341\n",
      "---number of yes in train 4207, in test 1082, in predict 1362, mcc score is 0.5478\n",
      "---mean score 0.5481\n",
      "Feature Number: 65\n",
      "---number of yes in train 4219, in test 1070, in predict 1573, mcc score is 0.5608\n",
      "---number of yes in train 4230, in test 1059, in predict 1441, mcc score is 0.5471\n",
      "---number of yes in train 4251, in test 1038, in predict 1396, mcc score is 0.5480\n",
      "---number of yes in train 4249, in test 1040, in predict 1456, mcc score is 0.5409\n",
      "---number of yes in train 4207, in test 1082, in predict 1343, mcc score is 0.5512\n",
      "---mean score 0.5496\n",
      "Feature Number: 60\n",
      "---number of yes in train 4219, in test 1070, in predict 1570, mcc score is 0.5597\n",
      "---number of yes in train 4230, in test 1059, in predict 1418, mcc score is 0.5362\n",
      "---number of yes in train 4251, in test 1038, in predict 1392, mcc score is 0.5347\n",
      "---number of yes in train 4249, in test 1040, in predict 1486, mcc score is 0.5267\n",
      "---number of yes in train 4207, in test 1082, in predict 1386, mcc score is 0.5430\n",
      "---mean score 0.5401\n",
      "Feature Number: 55\n",
      "---number of yes in train 4219, in test 1070, in predict 1588, mcc score is 0.5670\n",
      "---number of yes in train 4230, in test 1059, in predict 1352, mcc score is 0.5320\n",
      "---number of yes in train 4251, in test 1038, in predict 1377, mcc score is 0.5368\n",
      "---number of yes in train 4249, in test 1040, in predict 1505, mcc score is 0.5229\n",
      "---number of yes in train 4207, in test 1082, in predict 1405, mcc score is 0.5426\n",
      "---mean score 0.5403\n",
      "Feature Number: 50\n",
      "---number of yes in train 4219, in test 1070, in predict 1590, mcc score is 0.5656\n",
      "---number of yes in train 4230, in test 1059, in predict 1421, mcc score is 0.5354\n",
      "---number of yes in train 4251, in test 1038, in predict 1337, mcc score is 0.5429\n",
      "---number of yes in train 4249, in test 1040, in predict 1502, mcc score is 0.5293\n",
      "---number of yes in train 4207, in test 1082, in predict 1378, mcc score is 0.5481\n",
      "---mean score 0.5443\n",
      "Feature Number: 45\n",
      "---number of yes in train 4219, in test 1070, in predict 1581, mcc score is 0.5678\n",
      "---number of yes in train 4230, in test 1059, in predict 1393, mcc score is 0.5315\n",
      "---number of yes in train 4251, in test 1038, in predict 1400, mcc score is 0.5364\n",
      "---number of yes in train 4249, in test 1040, in predict 1533, mcc score is 0.5364\n",
      "---number of yes in train 4207, in test 1082, in predict 1427, mcc score is 0.5414\n",
      "---mean score 0.5427\n",
      "Feature Number: 40\n",
      "---number of yes in train 4219, in test 1070, in predict 1543, mcc score is 0.5583\n",
      "---number of yes in train 4230, in test 1059, in predict 1388, mcc score is 0.5366\n",
      "---number of yes in train 4251, in test 1038, in predict 1506, mcc score is 0.5495\n",
      "---number of yes in train 4249, in test 1040, in predict 1472, mcc score is 0.5434\n",
      "---number of yes in train 4207, in test 1082, in predict 1401, mcc score is 0.5446\n",
      "---mean score 0.5465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 35\n",
      "---number of yes in train 4219, in test 1070, in predict 1501, mcc score is 0.5562\n",
      "---number of yes in train 4230, in test 1059, in predict 1379, mcc score is 0.5400\n",
      "---number of yes in train 4251, in test 1038, in predict 1537, mcc score is 0.5455\n",
      "---number of yes in train 4249, in test 1040, in predict 1471, mcc score is 0.5267\n",
      "---number of yes in train 4207, in test 1082, in predict 1444, mcc score is 0.5425\n",
      "---mean score 0.5422\n",
      "Feature Number: 30\n",
      "---number of yes in train 4219, in test 1070, in predict 1496, mcc score is 0.5584\n",
      "---number of yes in train 4230, in test 1059, in predict 1364, mcc score is 0.5393\n",
      "---number of yes in train 4251, in test 1038, in predict 1488, mcc score is 0.5513\n",
      "---number of yes in train 4249, in test 1040, in predict 1445, mcc score is 0.5248\n",
      "---number of yes in train 4207, in test 1082, in predict 1461, mcc score is 0.5436\n",
      "---mean score 0.5435\n",
      "Feature Number: 25\n",
      "---number of yes in train 4219, in test 1070, in predict 1473, mcc score is 0.5533\n",
      "---number of yes in train 4230, in test 1059, in predict 1425, mcc score is 0.5523\n",
      "---number of yes in train 4251, in test 1038, in predict 1416, mcc score is 0.5608\n",
      "---number of yes in train 4249, in test 1040, in predict 1453, mcc score is 0.5417\n",
      "---number of yes in train 4207, in test 1082, in predict 1344, mcc score is 0.5471\n",
      "---mean score 0.5510\n",
      "Feature Number: 20\n",
      "---number of yes in train 4219, in test 1070, in predict 1463, mcc score is 0.5410\n",
      "---number of yes in train 4230, in test 1059, in predict 1374, mcc score is 0.5519\n",
      "---number of yes in train 4251, in test 1038, in predict 1422, mcc score is 0.5544\n",
      "---number of yes in train 4249, in test 1040, in predict 1456, mcc score is 0.5371\n",
      "---number of yes in train 4207, in test 1082, in predict 1396, mcc score is 0.5535\n",
      "---mean score 0.5476\n",
      "Feature Number: 15\n",
      "---number of yes in train 4219, in test 1070, in predict 1474, mcc score is 0.5493\n",
      "---number of yes in train 4230, in test 1059, in predict 1299, mcc score is 0.5431\n",
      "---number of yes in train 4251, in test 1038, in predict 1273, mcc score is 0.5375\n",
      "---number of yes in train 4249, in test 1040, in predict 1493, mcc score is 0.5175\n",
      "---number of yes in train 4207, in test 1082, in predict 1331, mcc score is 0.5508\n",
      "---mean score 0.5396\n"
     ]
    }
   ],
   "source": [
    "# recursively drop feature by decision tree\n",
    "\n",
    "np.random.RandomState(888)\n",
    "\n",
    "newX = deepcopy(X)\n",
    "\n",
    "# use the best parameter we get in the above parts\n",
    "para = {'class_weight': {0: 1, 1: 2.125}, \n",
    "        'criterion': 'entropy', \n",
    "        'max_depth': 10, \n",
    "        'random_state': 888\n",
    "       }\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(**para)\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state = 888)\n",
    "\n",
    "\n",
    "while newX.shape[1] > 10:\n",
    "    print(\"Feature Number: {:d}\".format(newX.shape[1]))\n",
    "    score_array = np.zeros(5) \n",
    "    for (ii, (train_index, test_index)) in enumerate(kf.split(newX, y)):\n",
    "        X_train, X_test = newX.loc[train_index], newX.loc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        dtree.fit(X_train, y_train)\n",
    "        y_predict = dtree.predict(X_test)\n",
    "        myscore = matthews_corrcoef(y_test, y_predict)\n",
    "        score_array[ii] = myscore\n",
    "        print(\"---number of yes in train {:d}, in test {:d}, in predict {:d}, mcc score is {:.4f}\".format(y_train.value_counts()[1],\\\n",
    "                                                                                                      y_test.value_counts()[1],\\\n",
    "                                                                                                      sum(y_predict),\\\n",
    "                                                                                                      myscore))\n",
    "    print(\"---mean score {:.4f}\".format(np.mean(score_array)))\n",
    "    feature_importance = dtree.fit(newX,y).feature_importances_\n",
    "    feature_importance_list = []\n",
    "    for (ii, col) in enumerate(newX.columns):\n",
    "        feature_importance_list.append((col, feature_importance[ii]))\n",
    "    feature_importance_list.sort(reverse=True, key=lambda occurance: occurance[1])\n",
    "    if len(feature_importance_list) > 1000:\n",
    "        drop_list = [ item[0] for item in feature_importance_list if item[1] == 0.0 ]\n",
    "    if len(feature_importance_list) <= 1000 and len(feature_importance_list) > 200:\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-20:] ]\n",
    "    if len(feature_importance_list) <= 200 and len(feature_importance_list) > 150:\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-10:] ]\n",
    "    if len(feature_importance_list) <= 150 and len(feature_importance_list):\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-5:] ]\n",
    "    newX.drop(columns = drop_list, inplace =True)\n",
    "    newX.to_csv(\".\\\\temp\\\\X_cross_feature_{:d}_dt.csv\".format(newX.shape[1]), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 385\n",
      "---number of yes in train 4219, in test 1070, in predict 1649, mcc score is 0.5957\n",
      "---number of yes in train 4230, in test 1059, in predict 1604, mcc score is 0.5916\n",
      "---number of yes in train 4251, in test 1038, in predict 1634, mcc score is 0.5729\n",
      "---number of yes in train 4249, in test 1040, in predict 1603, mcc score is 0.5724\n",
      "---number of yes in train 4207, in test 1082, in predict 1592, mcc score is 0.5900\n",
      "---mean score 0.5845\n",
      "Feature Number: 365\n",
      "---number of yes in train 4219, in test 1070, in predict 1617, mcc score is 0.5965\n",
      "---number of yes in train 4230, in test 1059, in predict 1610, mcc score is 0.5883\n",
      "---number of yes in train 4251, in test 1038, in predict 1631, mcc score is 0.5718\n",
      "---number of yes in train 4249, in test 1040, in predict 1612, mcc score is 0.5747\n",
      "---number of yes in train 4207, in test 1082, in predict 1592, mcc score is 0.5900\n",
      "---mean score 0.5843\n",
      "Feature Number: 345\n",
      "---number of yes in train 4219, in test 1070, in predict 1630, mcc score is 0.5995\n",
      "---number of yes in train 4230, in test 1059, in predict 1597, mcc score is 0.5907\n",
      "---number of yes in train 4251, in test 1038, in predict 1629, mcc score is 0.5705\n",
      "---number of yes in train 4249, in test 1040, in predict 1622, mcc score is 0.5705\n",
      "---number of yes in train 4207, in test 1082, in predict 1586, mcc score is 0.5870\n",
      "---mean score 0.5837\n",
      "Feature Number: 325\n",
      "---number of yes in train 4219, in test 1070, in predict 1623, mcc score is 0.5995\n",
      "---number of yes in train 4230, in test 1059, in predict 1621, mcc score is 0.5865\n",
      "---number of yes in train 4251, in test 1038, in predict 1651, mcc score is 0.5725\n",
      "---number of yes in train 4249, in test 1040, in predict 1612, mcc score is 0.5693\n",
      "---number of yes in train 4207, in test 1082, in predict 1577, mcc score is 0.5893\n",
      "---mean score 0.5834\n",
      "Feature Number: 305\n",
      "---number of yes in train 4219, in test 1070, in predict 1615, mcc score is 0.5997\n",
      "---number of yes in train 4230, in test 1059, in predict 1589, mcc score is 0.5909\n",
      "---number of yes in train 4251, in test 1038, in predict 1630, mcc score is 0.5748\n",
      "---number of yes in train 4249, in test 1040, in predict 1615, mcc score is 0.5731\n",
      "---number of yes in train 4207, in test 1082, in predict 1573, mcc score is 0.5904\n",
      "---mean score 0.5858\n",
      "Feature Number: 285\n",
      "---number of yes in train 4219, in test 1070, in predict 1603, mcc score is 0.5992\n",
      "---number of yes in train 4230, in test 1059, in predict 1578, mcc score is 0.5837\n",
      "---number of yes in train 4251, in test 1038, in predict 1630, mcc score is 0.5694\n",
      "---number of yes in train 4249, in test 1040, in predict 1599, mcc score is 0.5679\n",
      "---number of yes in train 4207, in test 1082, in predict 1570, mcc score is 0.5911\n",
      "---mean score 0.5823\n",
      "Feature Number: 265\n",
      "---number of yes in train 4219, in test 1070, in predict 1614, mcc score is 0.6071\n",
      "---number of yes in train 4230, in test 1059, in predict 1597, mcc score is 0.5943\n",
      "---number of yes in train 4251, in test 1038, in predict 1620, mcc score is 0.5736\n",
      "---number of yes in train 4249, in test 1040, in predict 1610, mcc score is 0.5689\n",
      "---number of yes in train 4207, in test 1082, in predict 1571, mcc score is 0.5864\n",
      "---mean score 0.5861\n",
      "Feature Number: 245\n",
      "---number of yes in train 4219, in test 1070, in predict 1618, mcc score is 0.6034\n",
      "---number of yes in train 4230, in test 1059, in predict 1580, mcc score is 0.5859\n",
      "---number of yes in train 4251, in test 1038, in predict 1601, mcc score is 0.5673\n",
      "---number of yes in train 4249, in test 1040, in predict 1587, mcc score is 0.5754\n",
      "---number of yes in train 4207, in test 1082, in predict 1576, mcc score is 0.5914\n",
      "---mean score 0.5847\n",
      "Feature Number: 225\n",
      "---number of yes in train 4219, in test 1070, in predict 1609, mcc score is 0.6012\n",
      "---number of yes in train 4230, in test 1059, in predict 1590, mcc score is 0.5934\n",
      "---number of yes in train 4251, in test 1038, in predict 1614, mcc score is 0.5769\n",
      "---number of yes in train 4249, in test 1040, in predict 1615, mcc score is 0.5704\n",
      "---number of yes in train 4207, in test 1082, in predict 1569, mcc score is 0.5878\n",
      "---mean score 0.5859\n",
      "Feature Number: 205\n",
      "---number of yes in train 4219, in test 1070, in predict 1606, mcc score is 0.6002\n",
      "---number of yes in train 4230, in test 1059, in predict 1603, mcc score is 0.5910\n",
      "---number of yes in train 4251, in test 1038, in predict 1624, mcc score is 0.5690\n",
      "---number of yes in train 4249, in test 1040, in predict 1607, mcc score is 0.5687\n",
      "---number of yes in train 4207, in test 1082, in predict 1584, mcc score is 0.5893\n",
      "---mean score 0.5836\n",
      "Feature Number: 185\n",
      "---number of yes in train 4219, in test 1070, in predict 1611, mcc score is 0.5998\n",
      "---number of yes in train 4230, in test 1059, in predict 1562, mcc score is 0.5923\n",
      "---number of yes in train 4251, in test 1038, in predict 1604, mcc score is 0.5766\n",
      "---number of yes in train 4249, in test 1040, in predict 1580, mcc score is 0.5735\n",
      "---number of yes in train 4207, in test 1082, in predict 1593, mcc score is 0.5880\n",
      "---mean score 0.5860\n",
      "Feature Number: 175\n",
      "---number of yes in train 4219, in test 1070, in predict 1606, mcc score is 0.5966\n",
      "---number of yes in train 4230, in test 1059, in predict 1566, mcc score is 0.5940\n",
      "---number of yes in train 4251, in test 1038, in predict 1609, mcc score is 0.5781\n",
      "---number of yes in train 4249, in test 1040, in predict 1608, mcc score is 0.5675\n",
      "---number of yes in train 4207, in test 1082, in predict 1578, mcc score is 0.5900\n",
      "---mean score 0.5853\n",
      "Feature Number: 165\n",
      "---number of yes in train 4219, in test 1070, in predict 1632, mcc score is 0.6071\n",
      "---number of yes in train 4230, in test 1059, in predict 1570, mcc score is 0.5894\n",
      "---number of yes in train 4251, in test 1038, in predict 1609, mcc score is 0.5772\n",
      "---number of yes in train 4249, in test 1040, in predict 1581, mcc score is 0.5751\n",
      "---number of yes in train 4207, in test 1082, in predict 1569, mcc score is 0.5914\n",
      "---mean score 0.5880\n",
      "Feature Number: 155\n",
      "---number of yes in train 4219, in test 1070, in predict 1610, mcc score is 0.6037\n",
      "---number of yes in train 4230, in test 1059, in predict 1573, mcc score is 0.5959\n",
      "---number of yes in train 4251, in test 1038, in predict 1602, mcc score is 0.5771\n",
      "---number of yes in train 4249, in test 1040, in predict 1591, mcc score is 0.5690\n",
      "---number of yes in train 4207, in test 1082, in predict 1578, mcc score is 0.5918\n",
      "---mean score 0.5875\n",
      "Feature Number: 145\n",
      "---number of yes in train 4219, in test 1070, in predict 1605, mcc score is 0.6005\n",
      "---number of yes in train 4230, in test 1059, in predict 1572, mcc score is 0.5880\n",
      "---number of yes in train 4251, in test 1038, in predict 1599, mcc score is 0.5687\n",
      "---number of yes in train 4249, in test 1040, in predict 1577, mcc score is 0.5733\n",
      "---number of yes in train 4207, in test 1082, in predict 1551, mcc score is 0.5924\n",
      "---mean score 0.5846\n",
      "Feature Number: 140\n",
      "---number of yes in train 4219, in test 1070, in predict 1604, mcc score is 0.5998\n",
      "---number of yes in train 4230, in test 1059, in predict 1576, mcc score is 0.5960\n",
      "---number of yes in train 4251, in test 1038, in predict 1600, mcc score is 0.5739\n",
      "---number of yes in train 4249, in test 1040, in predict 1570, mcc score is 0.5705\n",
      "---number of yes in train 4207, in test 1082, in predict 1568, mcc score is 0.5907\n",
      "---mean score 0.5862\n",
      "Feature Number: 135\n",
      "---number of yes in train 4219, in test 1070, in predict 1615, mcc score is 0.5997\n",
      "---number of yes in train 4230, in test 1059, in predict 1547, mcc score is 0.5907\n",
      "---number of yes in train 4251, in test 1038, in predict 1587, mcc score is 0.5735\n",
      "---number of yes in train 4249, in test 1040, in predict 1601, mcc score is 0.5702\n",
      "---number of yes in train 4207, in test 1082, in predict 1567, mcc score is 0.5883\n",
      "---mean score 0.5845\n",
      "Feature Number: 130\n",
      "---number of yes in train 4219, in test 1070, in predict 1628, mcc score is 0.5974\n",
      "---number of yes in train 4230, in test 1059, in predict 1575, mcc score is 0.5863\n",
      "---number of yes in train 4251, in test 1038, in predict 1605, mcc score is 0.5845\n",
      "---number of yes in train 4249, in test 1040, in predict 1586, mcc score is 0.5757\n",
      "---number of yes in train 4207, in test 1082, in predict 1557, mcc score is 0.5954\n",
      "---mean score 0.5878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 125\n",
      "---number of yes in train 4219, in test 1070, in predict 1611, mcc score is 0.5954\n",
      "---number of yes in train 4230, in test 1059, in predict 1588, mcc score is 0.5839\n",
      "---number of yes in train 4251, in test 1038, in predict 1593, mcc score is 0.5775\n",
      "---number of yes in train 4249, in test 1040, in predict 1587, mcc score is 0.5718\n",
      "---number of yes in train 4207, in test 1082, in predict 1565, mcc score is 0.5924\n",
      "---mean score 0.5842\n",
      "Feature Number: 120\n",
      "---number of yes in train 4219, in test 1070, in predict 1608, mcc score is 0.5970\n",
      "---number of yes in train 4230, in test 1059, in predict 1560, mcc score is 0.5919\n",
      "---number of yes in train 4251, in test 1038, in predict 1601, mcc score is 0.5819\n",
      "---number of yes in train 4249, in test 1040, in predict 1603, mcc score is 0.5706\n",
      "---number of yes in train 4207, in test 1082, in predict 1577, mcc score is 0.5947\n",
      "---mean score 0.5872\n",
      "Feature Number: 115\n",
      "---number of yes in train 4219, in test 1070, in predict 1624, mcc score is 0.5957\n",
      "---number of yes in train 4230, in test 1059, in predict 1564, mcc score is 0.5854\n",
      "---number of yes in train 4251, in test 1038, in predict 1602, mcc score is 0.5780\n",
      "---number of yes in train 4249, in test 1040, in predict 1574, mcc score is 0.5686\n",
      "---number of yes in train 4207, in test 1082, in predict 1547, mcc score is 0.5916\n",
      "---mean score 0.5839\n",
      "Feature Number: 110\n",
      "---number of yes in train 4219, in test 1070, in predict 1610, mcc score is 0.5965\n",
      "---number of yes in train 4230, in test 1059, in predict 1575, mcc score is 0.5854\n",
      "---number of yes in train 4251, in test 1038, in predict 1594, mcc score is 0.5745\n",
      "---number of yes in train 4249, in test 1040, in predict 1579, mcc score is 0.5665\n",
      "---number of yes in train 4207, in test 1082, in predict 1563, mcc score is 0.5947\n",
      "---mean score 0.5835\n",
      "Feature Number: 105\n",
      "---number of yes in train 4219, in test 1070, in predict 1629, mcc score is 0.5936\n",
      "---number of yes in train 4230, in test 1059, in predict 1541, mcc score is 0.5840\n",
      "---number of yes in train 4251, in test 1038, in predict 1588, mcc score is 0.5778\n",
      "---number of yes in train 4249, in test 1040, in predict 1574, mcc score is 0.5704\n",
      "---number of yes in train 4207, in test 1082, in predict 1558, mcc score is 0.5870\n",
      "---mean score 0.5826\n",
      "Feature Number: 100\n",
      "---number of yes in train 4219, in test 1070, in predict 1615, mcc score is 0.5970\n",
      "---number of yes in train 4230, in test 1059, in predict 1542, mcc score is 0.5792\n",
      "---number of yes in train 4251, in test 1038, in predict 1603, mcc score is 0.5777\n",
      "---number of yes in train 4249, in test 1040, in predict 1578, mcc score is 0.5658\n",
      "---number of yes in train 4207, in test 1082, in predict 1547, mcc score is 0.5935\n",
      "---mean score 0.5826\n",
      "Feature Number: 95\n",
      "---number of yes in train 4219, in test 1070, in predict 1632, mcc score is 0.5928\n",
      "---number of yes in train 4230, in test 1059, in predict 1580, mcc score is 0.5814\n",
      "---number of yes in train 4251, in test 1038, in predict 1600, mcc score is 0.5730\n",
      "---number of yes in train 4249, in test 1040, in predict 1603, mcc score is 0.5624\n",
      "---number of yes in train 4207, in test 1082, in predict 1568, mcc score is 0.5907\n",
      "---mean score 0.5801\n",
      "Feature Number: 90\n",
      "---number of yes in train 4219, in test 1070, in predict 1635, mcc score is 0.5947\n",
      "---number of yes in train 4230, in test 1059, in predict 1563, mcc score is 0.5857\n",
      "---number of yes in train 4251, in test 1038, in predict 1614, mcc score is 0.5741\n",
      "---number of yes in train 4249, in test 1040, in predict 1608, mcc score is 0.5694\n",
      "---number of yes in train 4207, in test 1082, in predict 1567, mcc score is 0.5919\n",
      "---mean score 0.5832\n",
      "Feature Number: 85\n",
      "---number of yes in train 4219, in test 1070, in predict 1611, mcc score is 0.5945\n",
      "---number of yes in train 4230, in test 1059, in predict 1576, mcc score is 0.5833\n",
      "---number of yes in train 4251, in test 1038, in predict 1611, mcc score is 0.5731\n",
      "---number of yes in train 4249, in test 1040, in predict 1588, mcc score is 0.5661\n",
      "---number of yes in train 4207, in test 1082, in predict 1558, mcc score is 0.5861\n",
      "---mean score 0.5806\n",
      "Feature Number: 80\n",
      "---number of yes in train 4219, in test 1070, in predict 1649, mcc score is 0.5931\n",
      "---number of yes in train 4230, in test 1059, in predict 1594, mcc score is 0.5761\n",
      "---number of yes in train 4251, in test 1038, in predict 1619, mcc score is 0.5729\n",
      "---number of yes in train 4249, in test 1040, in predict 1621, mcc score is 0.5563\n",
      "---number of yes in train 4207, in test 1082, in predict 1607, mcc score is 0.5809\n",
      "---mean score 0.5759\n",
      "Feature Number: 75\n",
      "---number of yes in train 4219, in test 1070, in predict 1647, mcc score is 0.5891\n",
      "---number of yes in train 4230, in test 1059, in predict 1592, mcc score is 0.5793\n",
      "---number of yes in train 4251, in test 1038, in predict 1636, mcc score is 0.5733\n",
      "---number of yes in train 4249, in test 1040, in predict 1591, mcc score is 0.5617\n",
      "---number of yes in train 4207, in test 1082, in predict 1580, mcc score is 0.5931\n",
      "---mean score 0.5793\n",
      "Feature Number: 70\n",
      "---number of yes in train 4219, in test 1070, in predict 1639, mcc score is 0.5849\n",
      "---number of yes in train 4230, in test 1059, in predict 1591, mcc score is 0.5768\n",
      "---number of yes in train 4251, in test 1038, in predict 1632, mcc score is 0.5698\n",
      "---number of yes in train 4249, in test 1040, in predict 1584, mcc score is 0.5625\n",
      "---number of yes in train 4207, in test 1082, in predict 1562, mcc score is 0.5842\n",
      "---mean score 0.5756\n",
      "Feature Number: 65\n",
      "---number of yes in train 4219, in test 1070, in predict 1622, mcc score is 0.5882\n",
      "---number of yes in train 4230, in test 1059, in predict 1583, mcc score is 0.5788\n",
      "---number of yes in train 4251, in test 1038, in predict 1615, mcc score is 0.5757\n",
      "---number of yes in train 4249, in test 1040, in predict 1577, mcc score is 0.5596\n",
      "---number of yes in train 4207, in test 1082, in predict 1554, mcc score is 0.5826\n",
      "---mean score 0.5770\n",
      "Feature Number: 60\n",
      "---number of yes in train 4219, in test 1070, in predict 1683, mcc score is 0.5831\n",
      "---number of yes in train 4230, in test 1059, in predict 1621, mcc score is 0.5632\n",
      "---number of yes in train 4251, in test 1038, in predict 1673, mcc score is 0.5637\n",
      "---number of yes in train 4249, in test 1040, in predict 1638, mcc score is 0.5514\n",
      "---number of yes in train 4207, in test 1082, in predict 1612, mcc score is 0.5832\n",
      "---mean score 0.5689\n",
      "Feature Number: 55\n",
      "---number of yes in train 4219, in test 1070, in predict 1672, mcc score is 0.5822\n",
      "---number of yes in train 4230, in test 1059, in predict 1643, mcc score is 0.5651\n",
      "---number of yes in train 4251, in test 1038, in predict 1675, mcc score is 0.5632\n",
      "---number of yes in train 4249, in test 1040, in predict 1649, mcc score is 0.5461\n",
      "---number of yes in train 4207, in test 1082, in predict 1615, mcc score is 0.5762\n",
      "---mean score 0.5666\n",
      "Feature Number: 50\n",
      "---number of yes in train 4219, in test 1070, in predict 1683, mcc score is 0.5822\n",
      "---number of yes in train 4230, in test 1059, in predict 1643, mcc score is 0.5642\n",
      "---number of yes in train 4251, in test 1038, in predict 1683, mcc score is 0.5587\n",
      "---number of yes in train 4249, in test 1040, in predict 1640, mcc score is 0.5482\n",
      "---number of yes in train 4207, in test 1082, in predict 1621, mcc score is 0.5721\n",
      "---mean score 0.5651\n",
      "Feature Number: 45\n",
      "---number of yes in train 4219, in test 1070, in predict 1690, mcc score is 0.5806\n",
      "---number of yes in train 4230, in test 1059, in predict 1635, mcc score is 0.5625\n",
      "---number of yes in train 4251, in test 1038, in predict 1688, mcc score is 0.5656\n",
      "---number of yes in train 4249, in test 1040, in predict 1633, mcc score is 0.5516\n",
      "---number of yes in train 4207, in test 1082, in predict 1615, mcc score is 0.5780\n",
      "---mean score 0.5677\n",
      "Feature Number: 40\n",
      "---number of yes in train 4219, in test 1070, in predict 1663, mcc score is 0.5755\n",
      "---number of yes in train 4230, in test 1059, in predict 1667, mcc score is 0.5594\n",
      "---number of yes in train 4251, in test 1038, in predict 1690, mcc score is 0.5571\n",
      "---number of yes in train 4249, in test 1040, in predict 1625, mcc score is 0.5499\n",
      "---number of yes in train 4207, in test 1082, in predict 1619, mcc score is 0.5735\n",
      "---mean score 0.5631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number: 35\n",
      "---number of yes in train 4219, in test 1070, in predict 1674, mcc score is 0.5764\n",
      "---number of yes in train 4230, in test 1059, in predict 1657, mcc score is 0.5573\n",
      "---number of yes in train 4251, in test 1038, in predict 1695, mcc score is 0.5595\n",
      "---number of yes in train 4249, in test 1040, in predict 1626, mcc score is 0.5497\n",
      "---number of yes in train 4207, in test 1082, in predict 1623, mcc score is 0.5672\n",
      "---mean score 0.5620\n",
      "Feature Number: 30\n",
      "---number of yes in train 4219, in test 1070, in predict 1667, mcc score is 0.5702\n",
      "---number of yes in train 4230, in test 1059, in predict 1658, mcc score is 0.5624\n",
      "---number of yes in train 4251, in test 1038, in predict 1706, mcc score is 0.5632\n",
      "---number of yes in train 4249, in test 1040, in predict 1640, mcc score is 0.5446\n",
      "---number of yes in train 4207, in test 1082, in predict 1632, mcc score is 0.5694\n",
      "---mean score 0.5620\n",
      "Feature Number: 25\n",
      "---number of yes in train 4219, in test 1070, in predict 1674, mcc score is 0.5562\n",
      "---number of yes in train 4230, in test 1059, in predict 1675, mcc score is 0.5372\n",
      "---number of yes in train 4251, in test 1038, in predict 1734, mcc score is 0.5384\n",
      "---number of yes in train 4249, in test 1040, in predict 1642, mcc score is 0.5297\n",
      "---number of yes in train 4207, in test 1082, in predict 1659, mcc score is 0.5506\n",
      "---mean score 0.5424\n",
      "Feature Number: 20\n",
      "---number of yes in train 4219, in test 1070, in predict 1692, mcc score is 0.5494\n",
      "---number of yes in train 4230, in test 1059, in predict 1663, mcc score is 0.5462\n",
      "---number of yes in train 4251, in test 1038, in predict 1744, mcc score is 0.5362\n",
      "---number of yes in train 4249, in test 1040, in predict 1660, mcc score is 0.5203\n",
      "---number of yes in train 4207, in test 1082, in predict 1656, mcc score is 0.5408\n",
      "---mean score 0.5386\n",
      "Feature Number: 15\n",
      "---number of yes in train 4219, in test 1070, in predict 1704, mcc score is 0.5528\n",
      "---number of yes in train 4230, in test 1059, in predict 1648, mcc score is 0.5452\n",
      "---number of yes in train 4251, in test 1038, in predict 1747, mcc score is 0.5399\n",
      "---number of yes in train 4249, in test 1040, in predict 1681, mcc score is 0.5272\n",
      "---number of yes in train 4207, in test 1082, in predict 1662, mcc score is 0.5367\n",
      "---mean score 0.5404\n"
     ]
    }
   ],
   "source": [
    "# recursively drop feature by random forest\n",
    "np.random.RandomState(888)\n",
    "\n",
    "newX = deepcopy(X)\n",
    "\n",
    "# use less estimators and smaller depthto accelerate the model\n",
    "para = {'class_weight': {0: 1, 1: 4}, \n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 10, \n",
    "        'n_estimators': 100, \n",
    "        'random_state': 888\n",
    "       }\n",
    "\n",
    "rftree = RandomForestClassifier(**para)\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state = 888)\n",
    "\n",
    "\n",
    "while newX.shape[1] > 10:\n",
    "    print(\"Feature Number: {:d}\".format(newX.shape[1]))\n",
    "    score_array = np.zeros(5) \n",
    "    for (ii, (train_index, test_index)) in enumerate(kf.split(newX, y)):\n",
    "        X_train, X_test = newX.loc[train_index], newX.loc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        rftree.fit(X_train, y_train)\n",
    "        y_predict = rftree.predict(X_test)\n",
    "        myscore = matthews_corrcoef(y_test, y_predict)\n",
    "        score_array[ii] = myscore\n",
    "        print(\"---number of yes in train {:d}, in test {:d}, in predict {:d}, mcc score is {:.4f}\".format(y_train.value_counts()[1],\\\n",
    "                                                                                                      y_test.value_counts()[1],\\\n",
    "                                                                                                      sum(y_predict),\\\n",
    "                                                                                                      myscore))\n",
    "    print(\"---mean score {:.4f}\".format(np.mean(score_array)))\n",
    "    feature_importance = rftree.fit(newX,y).feature_importances_\n",
    "    feature_importance_list = []\n",
    "    for (ii, col) in enumerate(newX.columns):\n",
    "        feature_importance_list.append((col, feature_importance[ii]))\n",
    "    feature_importance_list.sort(reverse=True, key=lambda occurance: occurance[1])\n",
    "    if len(feature_importance_list) > 1000:\n",
    "        drop_list = [ item[0] for item in feature_importance_list if item[1] == 0.0 ]\n",
    "    if len(feature_importance_list) <= 1000 and len(feature_importance_list) > 200:\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-20:] ]\n",
    "    if len(feature_importance_list) <= 200 and len(feature_importance_list) > 150:\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-10:] ]\n",
    "    if len(feature_importance_list) <= 150 and len(feature_importance_list):\n",
    "        drop_list = [ item[0] for item in feature_importance_list[-5:] ]\n",
    "    newX.drop(columns = drop_list, inplace =True)\n",
    "    newX.to_csv(\".\\\\temp\\\\X_cross_feature_{:d}_rf.csv\".format(newX.shape[1]), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the importance of each feature, in the above backward selection, which can show the Robustness of two models\n",
    "\n",
    "We will calculate the importance of each feature by summing up all the terms involved it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration     0.575804\n",
       "year         0.260976\n",
       "age          0.095638\n",
       "balance      0.043053\n",
       "pdays        0.012570\n",
       "campaign     0.008871\n",
       "previous     0.001923\n",
       "education    0.000591\n",
       "month        0.000575\n",
       "default      0.000000\n",
       "marital      0.000000\n",
       "job          0.000000\n",
       "housing      0.000000\n",
       "loan         0.000000\n",
       "contact      0.000000\n",
       "poutcome     0.000000\n",
       "weekday      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree, feature_num = 100\n",
    "feature_num = 100\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_dt.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 2.125}, \n",
    "        'criterion': 'entropy', \n",
    "        'max_depth': 10, \n",
    "        'random_state': 888\n",
    "       }\n",
    "dtree = DecisionTreeClassifier(**para)\n",
    "\n",
    "feature_importance = dtree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration     0.585236\n",
       "year         0.261837\n",
       "age          0.091517\n",
       "balance      0.050443\n",
       "pdays        0.008340\n",
       "campaign     0.002627\n",
       "marital      0.000000\n",
       "previous     0.000000\n",
       "job          0.000000\n",
       "weekday      0.000000\n",
       "default      0.000000\n",
       "housing      0.000000\n",
       "loan         0.000000\n",
       "contact      0.000000\n",
       "month        0.000000\n",
       "poutcome     0.000000\n",
       "education    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree, feature_num = 50\n",
    "feature_num = 50\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_dt.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 2.125}, \n",
    "        'criterion': 'entropy', \n",
    "        'max_depth': 10, \n",
    "        'random_state': 888\n",
    "       }\n",
    "dtree = DecisionTreeClassifier(**para)\n",
    "\n",
    "feature_importance = dtree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration     0.592220\n",
       "year         0.269256\n",
       "age          0.090320\n",
       "balance      0.032836\n",
       "pdays        0.015369\n",
       "marital      0.000000\n",
       "campaign     0.000000\n",
       "previous     0.000000\n",
       "job          0.000000\n",
       "weekday      0.000000\n",
       "default      0.000000\n",
       "housing      0.000000\n",
       "loan         0.000000\n",
       "contact      0.000000\n",
       "month        0.000000\n",
       "poutcome     0.000000\n",
       "education    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree, feature_num = 20\n",
    "feature_num = 20\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_dt.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 2.125}, \n",
    "        'criterion': 'entropy', \n",
    "        'max_depth': 10, \n",
    "        'random_state': 888\n",
    "       }\n",
    "dtree = DecisionTreeClassifier(**para)\n",
    "\n",
    "feature_importance = dtree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration     0.586377\n",
       "age          0.112398\n",
       "balance      0.087167\n",
       "campaign     0.078834\n",
       "pdays        0.056266\n",
       "year         0.051079\n",
       "previous     0.011529\n",
       "month        0.007397\n",
       "housing      0.005259\n",
       "poutcome     0.003694\n",
       "weekday      0.000000\n",
       "job          0.000000\n",
       "marital      0.000000\n",
       "default      0.000000\n",
       "loan         0.000000\n",
       "contact      0.000000\n",
       "education    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest, feature_num = 100\n",
    "feature_num = 100\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_rf.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 4}, \n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 10, \n",
    "        'n_estimators': 100, \n",
    "        'random_state': 888\n",
    "       }\n",
    "rftree = RandomForestClassifier(**para)\n",
    "\n",
    "feature_importance = rftree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\temp\\\\X_cross_feature_50_rf.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ad1143a2a512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolumns_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'balance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'duration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'campaign'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pdays'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'previous'\u001b[0m\u001b[1;33m,\u001b[0m                \u001b[1;34m'job'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'marital'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'education'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'housing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'contact'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'poutcome'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weekday'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnewX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\\\\temp\\\\X_cross_feature_{:d}_rf.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m para = {'class_weight': {0: 1, 1: 4}, \n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                     \u001b[1;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 )\n\u001b[1;32m-> 1191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m   2387\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m         )\n\u001b[0;32m   2391\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\temp\\\\X_cross_feature_50_rf.csv'"
     ]
    }
   ],
   "source": [
    "# random forest, feature_num = 50\n",
    "feature_num = 50\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_rf.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 4}, \n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 10, \n",
    "        'n_estimators': 100, \n",
    "        'random_state': 888\n",
    "       }\n",
    "rftree = RandomForestClassifier(**para)\n",
    "\n",
    "feature_importance = rftree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# random forest, feature_num = 20\n",
    "feature_num = 20\n",
    "columns_list = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\\\n",
    "                'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'year', 'weekday']\n",
    "newX = pd.read_csv(\".\\\\temp\\\\X_cross_feature_{:d}_rf.csv\".format(feature_num), engine = \"python\")\n",
    "\n",
    "para = {'class_weight': {0: 1, 1: 4}, \n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 10, \n",
    "        'n_estimators': 100, \n",
    "        'random_state': 888\n",
    "       }\n",
    "rftree = RandomForestClassifier(**para)\n",
    "\n",
    "feature_importance = rftree.fit(newX,y).feature_importances_\n",
    "feature_importance_list = []\n",
    "for (ii, col) in enumerate(newX.columns):\n",
    "    feature_importance_list.append((col, feature_importance[ii]))\n",
    "    \n",
    "feature_stat = pd.Series(index = columns_list)\n",
    "for col in columns_list:\n",
    "    feature_stat[col] = np.sum([item[1] for item in feature_importance_list if item[0].split('_')[0] == col])\n",
    "feature_stat.sort_values(ascending = False, inplace = True)\n",
    "feature_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
